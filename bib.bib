@TechReport{xu2022conformal,
  author      = {Xu, Chen and Xie, Yao},
  date        = {2022-06},
  institution = {arXiv},
  title       = {Conformal prediction set for time-series},
  doi         = {10.48550/arXiv.2206.07851},
  note        = {arXiv:2206.07851 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/2206.07851},
  urldate     = {2023-07-22},
  abstract    = {When building either prediction intervals for regression (with real-valued response) or prediction sets for classification (with categorical responses), uncertainty quantification is essential to studying complex machine learning methods. In this paper, we develop Ensemble Regularized Adaptive Prediction Set (ERAPS) to construct prediction sets for time-series (with categorical responses), based on the prior work of [Xu and Xie, 2021]. In particular, we allow unknown dependencies to exist within features and responses that arrive in sequence. Method-wise, ERAPS is a distribution-free and ensemble-based framework that is applicable for arbitrary classifiers. Theoretically, we bound the coverage gap without assuming data exchangeability and show asymptotic set convergence. Empirically, we demonstrate valid marginal and conditional coverage by ERAPS, which also tends to yield smaller prediction sets than competing methods.},
  annotation  = {Comment: Strongly accepted by the Workshop on Distribution-Free Uncertainty Quantification at ICML 2022},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2206.07851.pdf:application/pdf},
  keywords    = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Methodology},
}

@TechReport{kingma2017adam,
  author      = {Kingma, Diederik P. and Ba, Jimmy},
  date        = {2017-01},
  institution = {arXiv},
  title       = {Adam: {A} {Method} for {Stochastic} {Optimization}},
  doi         = {10.48550/arXiv.1412.6980},
  note        = {arXiv:1412.6980 [cs] type: article},
  url         = {http://arxiv.org/abs/1412.6980},
  urldate     = {2023-05-17},
  abstract    = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  annotation  = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1412.6980.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning},
  shorttitle  = {Adam},
}

@TechReport{xiao2017fashion,
  author      = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  date        = {2017-09},
  institution = {arXiv},
  title       = {Fashion-{MNIST}: a {Novel} {Image} {Dataset} for {Benchmarking} {Machine} {Learning} {Algorithms}},
  doi         = {10.48550/arXiv.1708.07747},
  note        = {arXiv:1708.07747 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1708.07747},
  urldate     = {2023-05-10},
  abstract    = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
  annotation  = {Comment: Dataset is freely available at https://github.com/zalandoresearch/fashion-mnist Benchmark is available at http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/},
  file        = {:xiao2017fashion - Fashion MNIST_ a Novel Image Dataset for Benchmarking Machine Learning Algorithms.pdf:PDF},
  keywords    = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
  shorttitle  = {Fashion-{MNIST}},
}

@Online{mw2023fidelity,
  author       = {Merriam-Webster},
  title        = {"Fidelity"},
  url          = {https://www.merriam-webster.com/dictionary/fidelity},
  language     = {en},
  organization = {Merriam-Webster},
  urldate      = {2023-03-23},
  abstract     = {the quality or state of being faithful; accuracy in details : exactness; the degree to which an electronic device (such as a record player, radio, or television) accurately reproduces its effect (such as sound or picture)… See the full definition},
}

@InProceedings{altmeyer2023endogenous,
  author    = {Altmeyer, Patrick and Angela, Giovan and Buszydlik, Aleksander and Dobiczek, Karol and van Deursen, Arie and Liem, Cynthia},
  booktitle = {First {IEEE} {Conference} on {Secure} and {Trustworthy} {Machine} {Learning}},
  title     = {Endogenous {Macrodynamics} in {Algorithmic} {Recourse}},
  file      = {:altmeyerendogenous - Endogenous Macrodynamics in Algorithmic Recourse.pdf:PDF},
  year      = {2023},
}

%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Patrick Altmeyer at 2022-12-13 12:58:22 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@Article{abadie2002instrumental,
  author        = {Abadie, Alberto and Angrist, Joshua and Imbens, Guido},
  title         = {Instrumental Variables Estimates of the Effect of Subsidized Training on the Quantiles of Trainee Earnings},
  number        = {1},
  pages         = {91--117},
  volume        = {70},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica : journal of the Econometric Society},
  shortjournal  = {Econometrica},
  year          = {2002},
}

@Article{abadie2003economic,
  author        = {Abadie, Alberto and Gardeazabal, Javier},
  title         = {The Economic Costs of Conflict: {{A}} Case Study of the {{Basque Country}}},
  number        = {1},
  pages         = {113--132},
  volume        = {93},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {American economic review},
  year          = {2003},
}

@InProceedings{ackerman2021machine,
  author        = {Ackerman, Samuel and Dube, Parijat and Farchi, Eitan and Raz, Orna and Zalmanovici, Marcel},
  booktitle     = {2021 {{IEEE}}/{{ACM Third International Workshop}} on {{Deep Learning}} for {{Testing}} and {{Testing}} for {{Deep Learning}} ({{DeepTest}})},
  title         = {Machine {{Learning Model Drift Detection Via Weak Data Slices}}},
  pages         = {1--8},
  publisher     = {{IEEE}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Article{allen2017referencedependent,
  author        = {Allen, Eric J and Dechow, Patricia M and Pope, Devin G and Wu, George},
  title         = {Reference-Dependent Preferences: {{Evidence}} from Marathon Runners},
  number        = {6},
  pages         = {1657--1672},
  volume        = {63},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Management Science},
  year          = {2017},
}

@Article{altmeyer2018option,
  author        = {Altmeyer, Patrick and Grapendal, Jacob Daniel and Pravosud, Makar and Quintana, Gand Derry},
  title         = {Option Pricing in the {{Heston}} Stochastic Volatility Model: An Empirical Evaluation},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2018},
}

@Article{altmeyer2021deep,
  author        = {Altmeyer, Patrick and Agusti, Marc and Vidal-Quadras Costa, Ignacio},
  title         = {Deep {{Vector Autoregression}} for {{Macroeconomic Data}}},
  url           = {https://thevoice.bse.eu/wp-content/uploads/2021/07/ds21-project-agusti-et-al.pdf},
  bdsk-url-1    = {https://thevoice.bse.eu/wp-content/uploads/2021/07/ds21-project-agusti-et-al.pdf},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Book{altmeyer2021deepvars,
  author        = {Altmeyer, Patrick},
  title         = {Deepvars: {{Deep Vector Autoregession}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Misc{altmeyer2022counterfactualexplanations,
  author        = {Altmeyer, Patrick},
  title         = {{{CounterfactualExplanations}}.Jl - a {{Julia}} Package for {{Counterfactual Explanations}} and {{Algorithmic Recourse}}},
  url           = {https://github.com/pat-alt/CounterfactualExplanations.jl},
  bdsk-url-1    = {https://github.com/pat-alt/CounterfactualExplanations.jl},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2022},
}

@Software{altmeyerCounterfactualExplanationsJlJulia2022,
  author        = {Altmeyer, Patrick},
  title         = {{{CounterfactualExplanations}}.Jl - a {{Julia}} Package for {{Counterfactual Explanations}} and {{Algorithmic Recourse}}},
  url           = {https://github.com/pat-alt/CounterfactualExplanations.jl},
  version       = {0.1.2},
  bdsk-url-1    = {https://github.com/pat-alt/CounterfactualExplanations.jl},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2022},
}

@Unpublished{angelopoulos2021gentle,
  author        = {Angelopoulos, Anastasios N. and Bates, Stephen},
  title         = {A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2107.07511},
  eprinttype    = {arxiv},
  file          = {:/Users/FA31DU/Zotero/storage/RKSUMYZG/Angelopoulos and Bates - 2021 - A gentle introduction to conformal prediction and .pdf:;:/Users/FA31DU/Zotero/storage/PRUEKRR3/2107.html:},
  year          = {2021},
}

@Misc{angelopoulos2022uncertainty,
  author        = {Angelopoulos, Anastasios and Bates, Stephen and Malik, Jitendra and Jordan, Michael I.},
  title         = {Uncertainty {{Sets}} for {{Image Classifiers}} Using {{Conformal Prediction}}},
  eprint        = {2009.14193},
  eprinttype    = {arxiv},
  abstract      = {Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network's probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90\%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.},
  archiveprefix = {arXiv},
  bdsk-url-1    = {http://arxiv.org/abs/2009.14193},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  file          = {:/Users/FA31DU/Zotero/storage/5BYIRBR2/Angelopoulos et al. - 2022 - Uncertainty Sets for Image Classifiers using Confo.pdf:;:/Users/FA31DU/Zotero/storage/2QJAKFKV/2009.html:},
  keywords      = {Computer Science - Computer Vision and Pattern Recognition, Mathematics - Statistics Theory, Statistics - Machine Learning},
  month         = sep,
  number        = {arXiv:2009.14193},
  primaryclass  = {cs, math, stat},
  publisher     = {{arXiv}},
  year          = {2022},
}

@Article{angelucci2009indirect,
  author        = {Angelucci, Manuela and De Giorgi, Giacomo},
  title         = {Indirect Effects of an Aid Program: How Do Cash Transfers Affect Ineligibles' Consumption?},
  number        = {1},
  pages         = {486--508},
  volume        = {99},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {American economic review},
  year          = {2009},
}

@Article{angrist1990lifetime,
  author        = {Angrist, Joshua D},
  title         = {Lifetime Earnings and the {{Vietnam}} Era Draft Lottery: Evidence from Social Security Administrative Records},
  pages         = {313--336},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The American Economic Review},
  year          = {1990},
}

@Unpublished{antoran2020getting,
  author        = {Antor{\'a}n, Javier and Bhatt, Umang and Adel, Tameem and Weller, Adrian and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel},
  title         = {Getting a Clue: {{A}} Method for Explaining Uncertainty Estimates},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2006.06848},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Article{arcones1992bootstrap,
  author        = {Arcones, Miguel A and Gine, Evarist},
  title         = {On the Bootstrap of {{U}} and {{V}} Statistics},
  pages         = {655--674},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Annals of Statistics},
  year          = {1992},
}

@Article{ariely2003coherent,
  author        = {Ariely, Dan and Loewenstein, George and Prelec, Drazen},
  title         = {``{{Coherent}} Arbitrariness'': {{Stable}} Demand Curves without Stable Preferences},
  number        = {1},
  pages         = {73--106},
  volume        = {118},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Quarterly journal of economics},
  year          = {2003},
}

@Article{ariely2006tom,
  author        = {Ariely, Dan and Loewenstein, George and Prelec, Drazen},
  title         = {Tom {{Sawyer}} and the Construction of Value},
  number        = {1},
  pages         = {1--10},
  volume        = {60},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Economic Behavior \& Organization},
  year          = {2006},
}

@Article{arrieta2020explainable,
  author        = {Arrieta, Alejandro Barredo and Diaz-Rodriguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  title         = {Explainable {{Artificial Intelligence}} ({{XAI}}): {{Concepts}}, Taxonomies, Opportunities and Challenges toward Responsible {{AI}}},
  pages         = {82--115},
  volume        = {58},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Information Fusion},
  year          = {2020},
}

@Article{auer2002finitetime,
  author        = {Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  title         = {Finite-Time Analysis of the Multiarmed Bandit Problem},
  number        = {2},
  pages         = {235--256},
  volume        = {47},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Machine learning},
  year          = {2002},
}

@Article{barabasi2016network,
  author        = {Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  title         = {Network {{Science}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Network Science},
  year          = {2016},
}

@Unpublished{bastounis2021mathematics,
  author        = {Bastounis, Alexander and Hansen, Anders C and Vla{\v c}i{\'c}, Verner},
  title         = {The Mathematics of Adversarial Attacks in {{AI}}--{{Why}} Deep Learning Is Unstable despite the Existence of Stable Neural Networks},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2109.06098},
  eprinttype    = {arxiv},
  year          = {2021},
}

@Article{bechara1997deciding,
  author        = {Bechara, Antoine and Damasio, Hanna and Tranel, Daniel and Damasio, Antonio R},
  title         = {Deciding Advantageously before Knowing the Advantageous Strategy},
  number        = {5304},
  pages         = {1293--1295},
  volume        = {275},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Science (New York, N.Y.)},
  shortjournal  = {Science},
  year          = {1997},
}

@Book{berlinet2011reproducing,
  author        = {Berlinet, Alain and Thomas-Agnan, Christine},
  title         = {Reproducing Kernel {{Hilbert}} Spaces in Probability and Statistics},
  publisher     = {{Springer Science \& Business Media}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2011},
}

@Misc{bernanke1990federal,
  author        = {Bernanke, Ben S},
  title         = {The Federal Funds Rate and the Channels of Monetary Transnission},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  publisher     = {{National Bureau of Economic Research Cambridge, Mass., USA}},
  year          = {1990},
}

@Article{besbes2014stochastic,
  author        = {Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
  title         = {Stochastic Multi-Armed-Bandit Problem with Non-Stationary Rewards},
  pages         = {199--207},
  volume        = {27},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in neural information processing systems},
  year          = {2014},
}

@Article{bholat2020impact,
  author        = {Bholat, D and Gharbawi, M and Thew, O},
  title         = {The {{Impact}} of {{Covid}} on {{Machine Learning}} and {{Data Science}} in {{UK Banking}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Bank of England Quarterly Bulletin, Q4},
  year          = {2020},
}

@Book{bishop2006pattern,
  author        = {Bishop, Christopher M},
  title         = {Pattern Recognition and Machine Learning},
  publisher     = {{springer}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2006},
}

@Article{blaom2020mlj,
  author        = {Blaom, Anthony D. and Kiraly, Franz and Lienart, Thibaut and Simillides, Yiannis and Arenas, Diego and Vollmer, Sebastian J.},
  title         = {{{MLJ}}: {{A Julia}} Package for Composable Machine Learning},
  doi           = {10.21105/joss.02704},
  issn          = {2475-9066},
  number        = {55},
  pages         = {2704},
  urldate       = {2022-10-27},
  volume        = {5},
  abstract      = {Blaom et al., (2020). MLJ: A Julia package for composable machine learning. Journal of Open Source Software, 5(55), 2704, https://doi.org/10.21105/joss.02704},
  bdsk-url-1    = {https://joss.theoj.org/papers/10.21105/joss.02704},
  bdsk-url-2    = {https://doi.org/10.21105/joss.02704},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  file          = {:/Users/FA31DU/Zotero/storage/7AY87FGP/Blaom et al. - 2020 - MLJ A Julia package for composable machine learni.pdf:;:/Users/FA31DU/Zotero/storage/D69YSMVF/joss.html:},
  journal       = {Journal of Open Source Software},
  langid        = {english},
  month         = nov,
  shorttitle    = {{{MLJ}}},
  year          = {2020},
}

@InProceedings{blundell2015weight,
  author        = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle     = {International Conference on Machine Learning},
  title         = {Weight Uncertainty in Neural Network},
  pages         = {1613--1622},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2015},
}

@Article{borch2022machine,
  author        = {Borch, Christian},
  title         = {Machine Learning, Knowledge Risk, and Principal-Agent Problems in Automated Trading},
  pages         = {101852},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Technology in Society},
  year          = {2022},
}

@Unpublished{borisov2021deep,
  author        = {Borisov, Vadim and Leemann, Tobias and Se{\ss}ler, Kathrin and Haug, Johannes and Pawelczyk, Martin and Kasneci, Gjergji},
  title         = {Deep Neural Networks and Tabular Data: {{A}} Survey},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2110.01889},
  eprinttype    = {arxiv},
  year          = {2021},
}

@Article{bramoulle2009identification,
  author        = {Bramoull{\'e}, Yann and Djebbari, Habiba and Fortin, Bernard},
  title         = {Identification of Peer Effects through Social Networks},
  number        = {1},
  pages         = {41--55},
  volume        = {150},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of econometrics},
  year          = {2009},
}

@Article{bramoulle2020peer,
  author        = {Bramoull{\'e}, Yann and Djebbari, Habiba and Fortin, Bernard},
  title         = {Peer Effects in Networks: {{A}} Survey},
  pages         = {603--629},
  volume        = {12},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Annual Review of Economics},
  year          = {2020},
}

@Unpublished{branco2015survey,
  author        = {Branco, Paula and Torgo, Luis and Ribeiro, Rita},
  title         = {A Survey of Predictive Modelling under Imbalanced Distributions},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1505.01658},
  eprinttype    = {arxiv},
  year          = {2015},
}

@Book{brock1991nonlinear,
  author        = {Brock, William Allen and Brock, William A and Hsieh, David Arthur and LeBaron, Blake Dean and Brock, William E},
  title         = {Nonlinear Dynamics, Chaos, and Instability: Statistical Theory and Economic Evidence},
  publisher     = {{MIT press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1991},
}

@InProceedings{buolamwini2018gender,
  author        = {Buolamwini, Joy and Gebru, Timnit},
  booktitle     = {Conference on Fairness, Accountability and Transparency},
  title         = {Gender Shades: {{Intersectional}} Accuracy Disparities in Commercial Gender Classification},
  pages         = {77--91},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2018},
}

@Unpublished{bussmann2020neural,
  author        = {Bussmann, Bart and Nys, Jannes and Latr{\'e}, Steven},
  title         = {Neural {{Additive Vector Autoregression Models}} for {{Causal Discovery}} in {{Time Series Data}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2010.09429},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Report{card1993minimum,
  author        = {Card, David and Krueger, Alan B},
  title         = {Minimum Wages and Employment: {{A}} Case Study of the Fast Food Industry in {{New Jersey}} and {{Pennsylvania}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  school        = {{National Bureau of Economic Research}},
  year          = {1993},
}

@InProceedings{carlini2017evaluating,
  author        = {Carlini, Nicholas and Wagner, David},
  booktitle     = {2017 Ieee Symposium on Security and Privacy (Sp)},
  title         = {Towards Evaluating the Robustness of Neural Networks},
  pages         = {39--57},
  publisher     = {{IEEE}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2017},
}

@Article{carlisle2019racist,
  author        = {Carlisle, M.},
  title         = {Racist Data Destruction? - a {{Boston}} Housing Dataset Controversy},
  url           = {https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8},
  bdsk-url-1    = {https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2019},
}

@Article{carrell2009does,
  author        = {Carrell, Scott E and Fullerton, Richard L and West, James E},
  title         = {Does Your Cohort Matter? {{Measuring}} Peer Effects in College Achievement},
  number        = {3},
  pages         = {439--464},
  volume        = {27},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Labor Economics},
  year          = {2009},
}

@Article{carrell2013natural,
  author        = {Carrell, Scott E and Sacerdote, Bruce I and West, James E},
  title         = {From Natural Variation to Optimal Policy? {{The}} Importance of Endogenous Peer Group Formation},
  number        = {3},
  pages         = {855--882},
  volume        = {81},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica : journal of the Econometric Society},
  shortjournal  = {Econometrica},
  year          = {2013},
}

@Article{carrizosa2021generating,
  author        = {Carrizosa, Emilio and Ramırez-Ayerbe, Jasone and Romero, Dolores},
  title         = {Generating {{Collective Counterfactual Explanations}} in {{Score-Based Classification}} via {{Mathematical Optimization}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Article{cascarino2022explainable,
  author        = {Cascarino, Giuseppe and Moscatelli, Mirko and Parlapiano, Fabio},
  title         = {Explainable {{Artificial Intelligence}}: Interpreting Default Forecasting Models Based on {{Machine Learning}}},
  number        = {674},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Bank of Italy Occasional Paper},
  year          = {2022},
}

@Article{chandola2009anomaly,
  author        = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  title         = {Anomaly Detection: {{A}} Survey},
  number        = {3},
  pages         = {1--58},
  volume        = {41},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {ACM computing surveys (CSUR)},
  year          = {2009},
}

@Article{chapelle2011empirical,
  author        = {Chapelle, Olivier and Li, Lihong},
  title         = {An Empirical Evaluation of Thompson Sampling},
  pages         = {2249--2257},
  volume        = {24},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in neural information processing systems},
  year          = {2011},
}

@Article{chetty2011adjustment,
  author        = {Chetty, Raj and Friedman, John N and Olsen, Tore and Pistaferri, Luigi},
  title         = {Adjustment Costs, Firm Responses, and Micro vs. Macro Labor Supply Elasticities: {{Evidence}} from {{Danish}} Tax Records},
  number        = {2},
  pages         = {749--804},
  volume        = {126},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The quarterly journal of economics},
  year          = {2011},
}

@Article{cortes1995supportvector,
  author        = {Cortes, Corinna and Vapnik, Vladimir},
  title         = {Support-Vector Networks},
  number        = {3},
  pages         = {273--297},
  volume        = {20},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Machine learning},
  year          = {1995},
}

@Article{crawford2019variable,
  author        = {Crawford, Lorin and Flaxman, Seth R and Runcie, Daniel E and West, Mike},
  title         = {Variable Prioritization in Nonlinear Black Box Methods: {{A}} Genetic Association Case Study},
  number        = {2},
  pages         = {958},
  volume        = {13},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The annals of applied statistics},
  year          = {2019},
}

@InProceedings{dai2022counterfactual,
  author        = {Dai, Xinyue and Keane, Mark T and Shalloo, Laurence and Ruelle, Elodie and Byrne, Ruth MJ},
  title         = {Counterfactual Explanations for Prediction and Diagnosis in Xai},
  eventtitle    = {Proceedings of the 2022 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  pages         = {215--226},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2022},
}

@Article{danielsson2021artificial,
  author        = {Danielsson, Jon and Macrae, Robert and Uthemann, Andreas},
  title         = {Artificial Intelligence and Systemic Risk},
  pages         = {106290},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Banking \& Finance},
  year          = {2021},
}

@Article{daxberger2021laplace,
  author        = {Daxberger, Erik and Kristiadi, Agustinus and Immer, Alexander and Eschenhagen, Runa and Bauer, Matthias and Hennig, Philipp},
  title         = {Laplace {{Redux-Effortless Bayesian Deep Learning}}},
  volume        = {34},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2021},
}

@Article{dehejia1999causal,
  author        = {Dehejia, Rajeev H and Wahba, Sadek},
  title         = {Causal Effects in Nonexperimental Studies: {{Reevaluating}} the Evaluation of Training Programs},
  number        = {448},
  pages         = {1053--1062},
  volume        = {94},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of the American statistical Association},
  year          = {1999},
}

@Article{dell2010persistent,
  author        = {Dell, Melissa},
  title         = {The Persistent Effects of {{Peru}}'s Mining Mita},
  number        = {6},
  pages         = {1863--1903},
  volume        = {78},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica : journal of the Econometric Society},
  shortjournal  = {Econometrica},
  year          = {2010},
}

@Article{denhengst2020reinforcement,
  author        = {den Hengst, Floris and Grua, Eoin Martino and el Hassouni, Ali and Hoogendoorn, Mark},
  title         = {Reinforcement Learning for Personalization: {{A}} Systematic Literature Review},
  issue         = {Preprint},
  pages         = {1--41},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Data Science},
  options       = {useprefix=true},
  year          = {2020},
}

@Article{deoliveira2021framework,
  author        = {de Oliveira, Raphael Mazzine Barbosa and Martens, David},
  title         = {A Framework and Benchmarking Study for Counterfactual Generating Methods on Tabular Data},
  number        = {16},
  pages         = {7274},
  volume        = {11},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Applied Sciences},
  options       = {useprefix=true},
  year          = {2021},
}

@Article{dhurandhar2018explanations,
  author        = {Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  title         = {Explanations Based on the Missing: {{Towards}} Contrastive Explanations with Pertinent Negatives},
  volume        = {31},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in neural information processing systems},
  year          = {2018},
}

@InProceedings{dombrowski2021diffeomorphic,
  author        = {Dombrowski, Ann-Kathrin and Gerken, Jan E and Kessel, Pan},
  booktitle     = {{{ICML Workshop}} on {{Invertible Neural Networks}}, {{Normalizing Flows}}, and {{Explicit Likelihood Models}}},
  title         = {Diffeomorphic Explanations with Normalizing Flows},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@InProceedings{dorffner1996neural,
  author        = {Dorffner, Georg},
  booktitle     = {Neural Network World},
  title         = {Neural Networks for Time Series Processing},
  publisher     = {{Citeseer}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1996},
}

@Article{epstein1979stability,
  author        = {Epstein, Seymour},
  title         = {The Stability of Behavior: {{I}}. {{On}} Predicting Most of the People Much of the Time.},
  number        = {7},
  pages         = {1097},
  volume        = {37},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of personality and social psychology},
  year          = {1979},
}

@Online{barocas2022fairness,
  author        = {Solon Barocas and Moritz Hardt and Arvind Narayanan},
  title         = {Fairness and Machine Learning},
  url           = {https://fairmlbook.org/index.html},
  urldate       = {2022-11-08},
  bdsk-url-1    = {https://fairmlbook.org/index.html},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  month         = dec,
  year          = {2022},
}

@Article{falk2006clean,
  author        = {Falk, Armin and Ichino, Andrea},
  title         = {Clean Evidence on Peer Effects},
  number        = {1},
  pages         = {39--57},
  volume        = {24},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of labor economics},
  year          = {2006},
}

@Unpublished{fan2020interpretability,
  author        = {Fan, Fenglei and Xiong, Jinjun and Wang, Ge},
  title         = {On Interpretability of Artificial Neural Networks},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2001.02522},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Article{fang2011dynamic,
  author        = {Fang, Hanming and Gavazza, Alessandro},
  title         = {Dynamic Inefficiencies in an Employment-Based Health Insurance System: {{Theory}} and Evidence},
  number        = {7},
  pages         = {3047--77},
  volume        = {101},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {American Economic Review},
  year          = {2011},
}

@Article{fehr2000cooperation,
  author        = {Fehr, Ernst and Gachter, Simon},
  title         = {Cooperation and Punishment in Public Goods Experiments},
  number        = {4},
  pages         = {980--994},
  volume        = {90},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {American Economic Review},
  year          = {2000},
}

@Article{fix1951important,
  author        = {Fix, E and Hodges, J},
  title         = {An Important Contribution to Nonparametric Discriminant Analysis and Density Estimation},
  number        = {57},
  pages         = {233--238},
  volume        = {3},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {International Statistical Review},
  year          = {1951},
}

@Book{friedman2008monetary,
  author        = {Friedman, Milton and Schwartz, Anna Jacobson},
  title         = {A Monetary History of the {{United States}}, 1867-1960},
  publisher     = {{Princeton University Press}},
  volume        = {14},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2008},
}

@InProceedings{gal2016dropout,
  author        = {Gal, Yarin and Ghahramani, Zoubin},
  booktitle     = {International Conference on Machine Learning},
  title         = {Dropout as a Bayesian Approximation: {{Representing}} Model Uncertainty in Deep Learning},
  pages         = {1050--1059},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2016},
}

@InProceedings{gal2017deep,
  author        = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  booktitle     = {International {{Conference}} on {{Machine Learning}}},
  title         = {Deep Bayesian Active Learning with Image Data},
  pages         = {1183--1192},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2017},
}

@Article{galizzi2019external,
  author        = {Galizzi, Matteo M and Navarro-Martinez, Daniel},
  title         = {On the External Validity of Social Preference Games: A Systematic Lab-Field Study},
  number        = {3},
  pages         = {976--1002},
  volume        = {65},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Management Science},
  year          = {2019},
}

@Article{gama2014survey,
  author        = {Gama, Jo{\~a}o and {\v Z}liobait{\.e}, Indr{\.e} and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  title         = {A Survey on Concept Drift Adaptation},
  number        = {4},
  pages         = {1--37},
  volume        = {46},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {ACM computing surveys (CSUR)},
  year          = {2014},
}

@Unpublished{garivier2008upperconfidence,
  author        = {Garivier, Aur{\'e}lien and Moulines, Eric},
  title         = {On Upper-Confidence Bound Policies for Non-Stationary Bandit Problems},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {0805.3415},
  eprinttype    = {arxiv},
  year          = {2008},
}

@Book{gelman2013bayesian,
  author        = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  title         = {Bayesian Data Analysis},
  publisher     = {{CRC press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2013},
}

@Article{gilbert1998immune,
  author        = {Gilbert, Daniel T and Pinel, Elizabeth C and Wilson, Timothy D and Blumberg, Stephen J and Wheatley, Thalia P},
  title         = {Immune Neglect: A Source of Durability Bias in Affective Forecasting.},
  number        = {3},
  pages         = {617},
  volume        = {75},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of personality and social psychology},
  year          = {1998},
}

@Article{gneezy2006uncertainty,
  author        = {Gneezy, Uri and List, John A and Wu, George},
  title         = {The Uncertainty Effect: {{When}} a Risky Prospect Is Valued Less than Its Worst Possible Outcome},
  number        = {4},
  pages         = {1283--1309},
  volume        = {121},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Quarterly Journal of Economics},
  year          = {2006},
}

@InCollection{goan2020bayesian,
  author        = {Goan, Ethan and Fookes, Clinton},
  booktitle     = {Case {{Studies}} in {{Applied Bayesian Data Science}}},
  title         = {Bayesian {{Neural Networks}}: {{An Introduction}} and {{Survey}}},
  pages         = {45--87},
  publisher     = {{Springer}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Article{goldsmith-pinkham2013social,
  author        = {Goldsmith-Pinkham, Paul and Imbens, Guido W},
  title         = {Social Networks and the Identification of Peer Effects},
  number        = {3},
  pages         = {253--264},
  volume        = {31},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Business \& Economic Statistics},
  year          = {2013},
}

@Unpublished{goodfellow2014explaining,
  author        = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  title         = {Explaining and Harnessing Adversarial Examples},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1412.6572},
  eprinttype    = {arxiv},
  year          = {2014},
}

@Book{goodfellow2016deep,
  author        = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  title         = {Deep {{Learning}}},
  publisher     = {{MIT Press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2016},
}

@Article{goodfriend2005incredible,
  author        = {Goodfriend, Marvin and King, Robert G},
  title         = {The Incredible {{Volcker}} Disinflation},
  number        = {5},
  pages         = {981--1015},
  volume        = {52},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Monetary Economics},
  year          = {2005},
}

@Article{graham2017econometric,
  author        = {Graham, Bryan S},
  title         = {An Econometric Model of Network Formation with Degree Heterogeneity},
  number        = {4},
  pages         = {1033--1063},
  volume        = {85},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica : journal of the Econometric Society},
  shortjournal  = {Econometrica},
  year          = {2017},
}

@Article{greene2012econometric,
  author        = {Greene, William H},
  title         = {Econometric Analysis, 71e},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Stern School of Business, New York University},
  year          = {2012},
}

@Article{grether1979economic,
  author        = {Grether, David M and Plott, Charles R},
  title         = {Economic Theory of Choice and the Preference Reversal Phenomenon},
  number        = {4},
  pages         = {623--638},
  volume        = {69},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The American Economic Review},
  year          = {1979},
}

@Article{gretton2012kernel,
  author        = {Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  title         = {A Kernel Two-Sample Test},
  number        = {1},
  pages         = {723--773},
  volume        = {13},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Journal of Machine Learning Research},
  year          = {2012},
}

@Unpublished{griffith2020name,
  author        = {Griffith, Alan},
  title         = {Name {{Your Friends}}, but {{Only Five}}? {{The Importance}} of {{Censoring}} in {{Peer Effects Estimates}} Using {{Social Network Data}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Unpublished{grinsztajn2022why,
  author        = {Grinsztajn, L{\'e}o and Oyallon, Edouard and Varoquaux, Ga{\"e}l},
  title         = {Why Do Tree-Based Models Still Outperform Deep Learning on Tabular Data?},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2207.08815},
  eprinttype    = {arxiv},
  year          = {2022},
}

@Misc{group2020detailed,
  author        = {Group, Open COVID-19 Data Working},
  title         = {Detailed {{Epidemiological Data}} from the {{COVID-19 Outbreak}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@InProceedings{gupta2011thompson,
  author        = {Gupta, Neha and Granmo, Ole-Christoffer and Agrawala, Ashok},
  booktitle     = {2011 10th {{International Conference}} on {{Machine Learning}} and {{Applications}} and {{Workshops}}},
  title         = {Thompson Sampling for Dynamic Multi-Armed Bandits},
  pages         = {484--489},
  publisher     = {{IEEE}},
  volume        = {1},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2011},
}

@Book{hamilton2020time,
  author        = {Hamilton, James Douglas},
  title         = {Time Series Analysis},
  publisher     = {{Princeton university press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Article{hamon2020robustness,
  author        = {Hamon, Ronan and Junklewitz, Henrik and Sanchez, Ignacio},
  title         = {Robustness and Explainability of Artificial Intelligence},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Publications Office of the European Union},
  year          = {2020},
}

@Article{hamzacebi2008improving,
  author        = {Hamza{\c c}ebi, Co{\c s}kun},
  title         = {Improving Artificial Neural Networks' Performance in Seasonal Time Series Forecasting},
  number        = {23},
  pages         = {4550--4559},
  volume        = {178},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Information Sciences},
  year          = {2008},
}

@InProceedings{hanneke2007bound,
  author        = {Hanneke, Steve},
  booktitle     = {Proceedings of the 24th International Conference on {{Machine}} Learning},
  title         = {A Bound on the Label Complexity of Agnostic Active Learning},
  pages         = {353--360},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2007},
}

@Article{hansen2020virtue,
  author        = {Hansen, Kristian Bondo},
  title         = {The Virtue of Simplicity: {{On}} Machine Learning Models in Algorithmic Trading},
  number        = {1},
  pages         = {2053951720926558},
  volume        = {7},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Big Data \& Society},
  year          = {2020},
}

@Article{hartland2006multiarmed,
  author        = {Hartland, C{\'e}dric and Gelly, Sylvain and Baskiotis, Nicolas and Teytaud, Olivier and Sebag, Michele},
  title         = {Multi-Armed Bandit, Dynamic Environments and Meta-Bandits},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2006},
}

@Article{heckman1985alternative,
  author        = {Heckman, James J and Robb Jr, Richard},
  title         = {Alternative Methods for Evaluating the Impact of Interventions: {{An}} Overview},
  number        = {1-2},
  pages         = {239--267},
  volume        = {30},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of econometrics},
  year          = {1985},
}

@Article{hershfield2011increasing,
  author        = {Hershfield, Hal E and Goldstein, Daniel G and Sharpe, William F and Fox, Jesse and Yeykelis, Leo and Carstensen, Laura L and Bailenson, Jeremy N},
  title         = {Increasing Saving Behavior through Age-Progressed Renderings of the Future Self},
  issue         = {SPL},
  pages         = {S23--S37},
  volume        = {48},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Marketing Research},
  year          = {2011},
}

@InProceedings{ho1995random,
  author        = {Ho, Tin Kam},
  booktitle     = {Proceedings of 3rd International Conference on Document Analysis and Recognition},
  title         = {Random Decision Forests},
  pages         = {278--282},
  publisher     = {{IEEE}},
  volume        = {1},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1995},
}

@Article{hochreiter1997long,
  author        = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  title         = {Long Short-Term Memory},
  number        = {8},
  pages         = {1735--1780},
  volume        = {9},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Neural computation},
  year          = {1997},
}

@Unpublished{hoff2021bayesoptimal,
  author        = {Hoff, Peter},
  title         = {Bayes-Optimal Prediction with Frequentist Coverage Control},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2105.14045},
  eprinttype    = {arxiv},
  file          = {:/Users/FA31DU/Zotero/storage/IQK27WVA/Hoff - 2021 - Bayes-optimal prediction with frequentist coverage.pdf:;:/Users/FA31DU/Zotero/storage/K8EAZA25/2105.html:},
  year          = {2021},
}

@Misc{hoffman1994german,
  author        = {Hoffman, Hans},
  title         = {German {{Credit Data}}},
  url           = {https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)},
  bdsk-url-1    = {https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1994},
}

@Online{hoffmanGermanCreditData1994,
  author        = {Hoffman, Hans},
  title         = {German {{Credit Data}}},
  url           = {https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)},
  bdsk-url-1    = {https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1994},
}

@Unpublished{houlsby2011bayesian,
  author        = {Houlsby, Neil and Husz{\'a}r, Ferenc and Ghahramani, Zoubin and Lengyel, M{\'a}t{\'e}},
  title         = {Bayesian Active Learning for Classification and Preference Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1112.5745},
  eprinttype    = {arxiv},
  year          = {2011},
}

@Article{hsee1996evaluability,
  author        = {Hsee, Christopher K},
  title         = {The Evaluability Hypothesis: {{An}} Explanation for Preference Reversals between Joint and Separate Evaluations of Alternatives},
  number        = {3},
  pages         = {247--257},
  volume        = {67},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Organizational behavior and human decision processes},
  year          = {1996},
}

@Article{hsee2004music,
  author        = {Hsee, Christopher K and Rottenstreich, Yuval},
  title         = {Music, Pandas, and Muggers: On the Affective Psychology of Value.},
  number        = {1},
  pages         = {23},
  volume        = {133},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Experimental Psychology: General},
  year          = {2004},
}

@Article{hsieh2016social,
  author        = {Hsieh, Chih-Sheng and Lee, Lung Fei},
  title         = {A Social Interactions Model with Endogenous Friendship Formation and Selectivity},
  number        = {2},
  pages         = {301--319},
  volume        = {31},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Applied Econometrics},
  year          = {2016},
}

@Unpublished{immer2020improving,
  author        = {Immer, Alexander and Korzepa, Maciej and Bauer, Matthias},
  title         = {Improving Predictions of Bayesian Neural Networks via Local Linearization},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2008.08400},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Unpublished{innes2018fashionable,
  author        = {Innes, Michael and Saba, Elliot and Fischer, Keno and Gandhi, Dhairya and Rudilosso, Marco Concetto and Joy, Neethu Mariya and Karmali, Tejan and Pal, Avik and Shah, Viral},
  title         = {Fashionable Modelling with Flux},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1811.01457},
  eprinttype    = {arxiv},
  year          = {2018},
}

@Article{innes2018flux,
  author        = {Innes, Mike},
  title         = {Flux: {{Elegant}} Machine Learning with {{Julia}}},
  number        = {25},
  pages         = {602},
  volume        = {3},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Open Source Software},
  year          = {2018},
}

@Unpublished{ish-horowicz2019interpreting,
  author        = {Ish-Horowicz, Jonathan and Udwin, Dana and Flaxman, Seth and Filippi, Sarah and Crawford, Lorin},
  title         = {Interpreting Deep Neural Networks through Variable Importance},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1901.09839},
  eprinttype    = {arxiv},
  year          = {2019},
}

@InProceedings{jabbari2017fairness,
  author        = {Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
  booktitle     = {International {{Conference}} on {{Machine Learning}}},
  title         = {Fairness in Reinforcement Learning},
  pages         = {1617--1626},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2017},
}

@Article{jackson2007meeting,
  author        = {Jackson, Matthew O and Rogers, Brian W},
  title         = {Meeting Strangers and Friends of Friends: {{How}} Random Are Social Networks?},
  number        = {3},
  pages         = {890--915},
  volume        = {97},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {American Economic Review},
  year          = {2007},
}

@Unpublished{jeanneret2022diffusion,
  author        = {Jeanneret, Guillaume and Simon, Lo{\"\i}c and Jurie, Fr{\'e}d{\'e}ric},
  title         = {Diffusion {{Models}} for {{Counterfactual Explanations}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2203.15636},
  eprinttype    = {arxiv},
  year          = {2022},
}

@Article{johansson2005failure,
  author        = {Johansson, Petter and Hall, Lars and Sikstr{\"o}m, Sverker and Olsson, Andreas},
  title         = {Failure to Detect Mismatches between Intention and Outcome in a Simple Decision Task},
  number        = {5745},
  pages         = {116--119},
  volume        = {310},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Science (New York, N.Y.)},
  shortjournal  = {Science},
  year          = {2005},
}

@Article{johnsson2021estimation,
  author        = {Johnsson, Ida and Moon, Hyungsik Roger},
  title         = {Estimation of Peer Effects in Endogenous Social Networks: {{Control}} Function Approach},
  number        = {2},
  pages         = {328--345},
  volume        = {103},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Review of Economics and Statistics},
  year          = {2021},
}

@Article{jolliffe2003modified,
  author        = {Jolliffe, Ian T and Trendafilov, Nickolay T and Uddin, Mudassir},
  title         = {A Modified Principal Component Technique Based on the {{LASSO}}},
  number        = {3},
  pages         = {531--547},
  volume        = {12},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of computational and Graphical Statistics},
  year          = {2003},
}

@Article{joseph2021forecasting,
  author        = {Joseph, Andreas and Kalamara, Eleni and Kapetanios, George and Potjagailo, Galina},
  title         = {Forecasting Uk Inflation Bottom Up},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Unpublished{joshi2019realistic,
  author        = {Joshi, Shalmali and Koyejo, Oluwasanmi and Vijitbenjaronk, Warut and Kim, Been and Ghosh, Joydeep},
  title         = {Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1907.09615},
  eprinttype    = {arxiv},
  year          = {2019},
}

@Unpublished{jospin2020handson,
  author        = {Jospin, Laurent Valentin and Buntine, Wray and Boussaid, Farid and Laga, Hamid and Bennamoun, Mohammed},
  title         = {Hands-on {{Bayesian Neural Networks}}--a {{Tutorial}} for {{Deep Learning Users}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2007.06823},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Misc{kaggle2011give,
  author        = {Kaggle},
  title         = {Give Me Some Credit, {{Improve}} on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the next Two Years.},
  url           = {https://www.kaggle.com/c/GiveMeSomeCredit},
  bdsk-url-1    = {https://www.kaggle.com/c/GiveMeSomeCredit},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  publisher     = {{Kaggle}},
  year          = {2011},
}

@online{kagglecompetitionGiveMeCredit,
	author = {Kaggle Competition},
	date-added = {2022-12-13 12:58:01 +0100},
	date-modified = {2022-12-13 12:58:01 +0100},
	title = {Give Me Some Credit, {{Improve}} on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the next Two Years.},
	url = {https://www.kaggle.com/c/GiveMeSomeCredit},
	bdsk-url-1 = {https://www.kaggle.com/c/GiveMeSomeCredit}}

@Article{kahneman1979prospect,
  author        = {Kahneman, Daniel and Tversky, Amos},
  title         = {Prospect {{Theory}}: {{An Analysis}} of {{Decision}} under {{Risk}}},
  pages         = {263--291},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica: Journal of the Econometric Society},
  year          = {1979},
}

@Article{kahneman1990experimental,
  author        = {Kahneman, Daniel and Knetsch, Jack L and Thaler, Richard H},
  title         = {Experimental Tests of the Endowment Effect and the {{Coase}} Theorem},
  number        = {6},
  pages         = {1325--1348},
  volume        = {98},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of political Economy},
  year          = {1990},
}

@Article{kahneman1992reference,
  author        = {Kahneman, Daniel},
  title         = {Reference Points, Anchors, Norms, and Mixed Feelings},
  number        = {2},
  pages         = {296--312},
  volume        = {51},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Organizational behavior and human decision processes},
  year          = {1992},
}

@Unpublished{karimi2020algorithmic,
  author        = {Karimi, Amir-Hossein and Von K{\"u}gelgen, Julius and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  title         = {Algorithmic Recourse under Imperfect Causal Knowledge: A Probabilistic Approach},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2006.06831},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Unpublished{karimi2020survey,
  author        = {Karimi, Amir-Hossein and Barthe, Gilles and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  title         = {A Survey of Algorithmic Recourse: Definitions, Formulations, Solutions, and Prospects},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2010.04050},
  eprinttype    = {arxiv},
  year          = {2020},
}

@InProceedings{karimi2021algorithmic,
  author        = {Karimi, Amir-Hossein and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  booktitle     = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  title         = {Algorithmic Recourse: From Counterfactual Explanations to Interventions},
  pages         = {353--362},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@InProceedings{kaur2020interpreting,
  author        = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
  booktitle     = {Proceedings of the 2020 {{CHI}} Conference on Human Factors in Computing Systems},
  title         = {Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning},
  pages         = {1--14},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Article{kehoe2021defence,
  author        = {Kehoe, Aidan and Wittek, Peter and Xue, Yanbo and Pozas-Kerstjens, Alejandro},
  title         = {Defence against Adversarial Attacks Using Classical and Quantum-Enhanced {{Boltzmann}} Machines},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Machine Learning: Science and Technology},
  year          = {2021},
}

@Unpublished{kendall2017what,
  author        = {Kendall, Alex and Gal, Yarin},
  title         = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1703.04977},
  eprinttype    = {arxiv},
  year          = {2017},
}

@Article{kihoro2004seasonal,
  author        = {Kihoro, J and Otieno, RO and Wafula, C},
  title         = {Seasonal Time Series Forecasting: {{A}} Comparative Study of {{ARIMA}} and {{ANN}} Models},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2004},
}

@Book{kilian2017structural,
  author        = {Kilian, Lutz and L{\"u}tkepohl, Helmut},
  title         = {Structural Vector Autoregressive Analysis},
  publisher     = {{Cambridge University Press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2017},
}

@Unpublished{kingma2014adam,
  author        = {Kingma, Diederik P and Ba, Jimmy},
  title         = {Adam: {{A}} Method for Stochastic Optimization},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1412.6980},
  eprinttype    = {arxiv},
  year          = {2014},
}

@Article{kirsch2019batchbald,
  author        = {Kirsch, Andreas and Van Amersfoort, Joost and Gal, Yarin},
  title         = {Batchbald: {{Efficient}} and Diverse Batch Acquisition for Deep Bayesian Active Learning},
  pages         = {7026--7037},
  volume        = {32},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in neural information processing systems},
  year          = {2019},
}

@Unpublished{kuiper2021exploring,
  author        = {Kuiper, Ouren and van den Berg, Martin and van den Burgt, Joost and Leijnen, Stefan},
  title         = {Exploring {{Explainable AI}} in the {{Financial Sector}}: {{Perspectives}} of {{Banks}} and {{Supervisory Authorities}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2111.02244},
  eprinttype    = {arxiv},
  year          = {2021},
}

@Article{kydland1982time,
  author        = {Kydland, Finn E and Prescott, Edward C},
  title         = {Time to Build and Aggregate Fluctuations},
  pages         = {1345--1370},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica: Journal of the Econometric Society},
  year          = {1982},
}

@Unpublished{lachapelle2019gradientbased,
  author        = {Lachapelle, S{\'e}bastien and Brouillard, Philippe and Deleu, Tristan and Lacoste-Julien, Simon},
  title         = {Gradient-Based Neural Dag Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1906.02226},
  eprinttype    = {arxiv},
  year          = {2019},
}

@InProceedings{lakkaraju2020how,
  author        = {Lakkaraju, Himabindu and Bastani, Osbert},
  booktitle     = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  title         = {" {{How}} Do {{I}} Fool You?" {{Manipulating User Trust}} via {{Misleading Black Box Explanations}}},
  pages         = {79--85},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@InProceedings{lakkaraju2020how,
  author        = {Lakkaraju, Himabindu and Bastani, Osbert},
  booktitle     = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  title         = {" {{How Do I Fool You}}?" {{Manipulating User Trust}} via {{Misleading Black Box Explanations}}},
  pages         = {79--85},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Unpublished{lakshminarayanan2016simple,
  author        = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  title         = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1612.01474},
  eprinttype    = {arxiv},
  year          = {2016},
}

@Unpublished{laugel2017inverse,
  author        = {Laugel, Thibault and Lesot, Marie-Jeanne and Marsala, Christophe and Renard, Xavier and Detyniecki, Marcin},
  title         = {Inverse Classification for Comparison-Based Interpretability in Machine Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1712.08443},
  eprinttype    = {arxiv},
  shortjournal  = {arXiv preprint arXiv:1712.08443},
  year          = {2017},
}

@Thesis{lawrence2001variational,
  author        = {Lawrence, Neil David},
  title         = {Variational Inference in Probabilistic Models},
  type          = {phdthesis},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  school        = {{University of Cambridge}},
  year          = {2001},
}

@Article{lecun1998mnist,
  author        = {LeCun, Yann},
  title         = {The {{MNIST}} Database of Handwritten Digits},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  shortjournal  = {http://yann. lecun. com/exdb/mnist/},
  year          = {1998},
}

@Article{lee2003best,
  author        = {Lee, Lung-fei},
  title         = {Best Spatial Two-Stage Least Squares Estimators for a Spatial Autoregressive Model with Autoregressive Disturbances},
  number        = {4},
  pages         = {307--335},
  volume        = {22},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometric Reviews},
  year          = {2003},
}

@Article{lerner2013financial,
  author        = {Lerner, Jennifer S and Li, Ye and Weber, Elke U},
  title         = {The Financial Costs of Sadness},
  number        = {1},
  pages         = {72--79},
  volume        = {24},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Psychological science},
  year          = {2013},
}

@Article{list2004neoclassical,
  author        = {List, John A},
  title         = {Neoclassical Theory versus Prospect Theory: {{Evidence}} from the Marketplace},
  number        = {2},
  pages         = {615--625},
  volume        = {72},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Econometrica : journal of the Econometric Society},
  shortjournal  = {Econometrica},
  year          = {2004},
}

@Article{lucas1976econometric,
  author        = {Lucas, JR},
  title         = {Econometric Policy Evaluation: A Critique `, in {{K}}. {{Brunner}} and {{A Meltzer}}, {{The Phillips}} Curve and Labor Markets, {{North Holland}}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {1976},
}

@InProceedings{lundberg2017unified,
  author        = {Lundberg, Scott M and Lee, Su-In},
  booktitle     = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  title         = {A Unified Approach to Interpreting Model Predictions},
  pages         = {4768--4777},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2017},
}

@Book{lutkepohl2005new,
  author        = {L{\"u}tkepohl, Helmut},
  title         = {New Introduction to Multiple Time Series Analysis},
  publisher     = {{Springer Science \& Business Media}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2005},
}

@Article{madrian2001power,
  author        = {Madrian, Brigitte C and Shea, Dennis F},
  title         = {The Power of Suggestion: {{Inertia}} in 401 (k) Participation and Savings Behavior},
  number        = {4},
  pages         = {1149--1187},
  volume        = {116},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Quarterly journal of economics},
  year          = {2001},
}

@Book{manning2008introduction,
  author        = {Manning, Christopher D and Sch{\"u}tze, Hinrich and Raghavan, Prabhakar},
  title         = {Introduction to Information Retrieval},
  publisher     = {{Cambridge university press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2008},
}

@misc{manokhin2022awesome,
	author = {Manokhin, Valery},
	date-added = {2022-12-13 12:58:01 +0100},
	date-modified = {2022-12-13 12:58:01 +0100},
	title = {Awesome Conformal Prediction}}

@Article{manski1993identification,
  author        = {Manski, Charles F},
  title         = {Identification of Endogenous Social Effects: {{The}} Reflection Problem},
  number        = {3},
  pages         = {531--542},
  volume        = {60},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The review of economic studies},
  year          = {1993},
}

@Article{markle2018goals,
  author        = {Markle, Alex and Wu, George and White, Rebecca and Sackett, Aaron},
  title         = {Goals as Reference Points in Marathon Running: {{A}} Novel Test of Reference Dependence},
  number        = {1},
  pages         = {19--50},
  volume        = {56},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Risk and Uncertainty},
  year          = {2018},
}

@Article{masini2021machine,
  author        = {Masini, Ricardo P and Medeiros, Marcelo C and Mendes, Eduardo F},
  title         = {Machine Learning Advances for Time Series Forecasting},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Economic Surveys},
  year          = {2021},
}

@Article{mccracken2016fredmd,
  author        = {McCracken, Michael W and Ng, Serena},
  title         = {{{FRED-MD}}: {{A}} Monthly Database for Macroeconomic Research},
  number        = {4},
  pages         = {574--589},
  volume        = {34},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Business \& Economic Statistics},
  year          = {2016},
}

@Article{mcculloch1990logical,
  author        = {McCulloch, Warren S and Pitts, Walter},
  title         = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  number        = {1},
  pages         = {99--115},
  volume        = {52},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Bulletin of mathematical biology},
  year          = {1990},
}

@Article{migut2015visualizing,
  author        = {Migut, MA and Worring, Marcel and Veenman, Cor J},
  title         = {Visualizing Multi-Dimensional Decision Boundaries in {{2D}}},
  number        = {1},
  pages         = {273--295},
  volume        = {29},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Data Mining and Knowledge Discovery},
  year          = {2015},
}

@Article{miller2019explanation,
  author        = {Miller, Tim},
  title         = {Explanation in Artificial Intelligence: {{Insights}} from the Social Sciences},
  pages         = {1--38},
  volume        = {267},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Artificial intelligence},
  year          = {2019},
}

@InProceedings{miller2020strategic,
  author        = {Miller, John and Milli, Smitha and Hardt, Moritz},
  booktitle     = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  title         = {Strategic {{Classification}} Is {{Causal Modeling}} in {{Disguise}}},
  eventtitle    = {International {{Conference}} on {{Machine Learning}}},
  pages         = {6917--6926},
  publisher     = {{PMLR}},
  url           = {https://proceedings.mlr.press/v119/miller20b.html},
  urldate       = {2022-11-03},
  abstract      = {Consequential decision-making incentivizes individuals to strategically adapt their behavior to the specifics of the decision rule. While a long line of work has viewed strategic adaptation as gaming and attempted to mitigate its effects, recent work has instead sought to design classifiers that incentivize individuals to improve a desired quality. Key to both accounts is a cost function that dictates which adaptations are rational to undertake. In this work, we develop a causal framework for strategic adaptation. Our causal perspective clearly distinguishes between gaming and improvement and reveals an important obstacle to incentive design. We prove any procedure for designing classifiers that incentivize improvement must inevitably solve a non-trivial causal inference problem. We show a similar result holds for designing cost functions that satisfy the requirements of previous work. With the benefit of hindsight, our results show much of the prior work on strategic classification is causal modeling in disguise.},
  bdsk-url-1    = {https://proceedings.mlr.press/v119/miller20b.html},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  file          = {:/Users/FA31DU/Zotero/storage/46I2QMPI/Miller et al. - 2020 - Strategic Classification is Causal Modeling in Dis.pdf:;:/Users/FA31DU/Zotero/storage/NWREET6B/Miller et al. - 2020 - Strategic Classification is Causal Modeling in Dis.pdf:},
  issn          = {2640-3498},
  langid        = {english},
  month         = nov,
  year          = {2020},
}

@Article{mischel1988nature,
  author        = {Mischel, Walter and Shoda, Yuichi and Peake, Philip K},
  title         = {The Nature of Adolescent Competencies Predicted by Preschool Delay of Gratification.},
  number        = {4},
  pages         = {687},
  volume        = {54},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of personality and social psychology},
  year          = {1988},
}

@InProceedings{mittelstadt2019explaining,
  author        = {Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
  booktitle     = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
  title         = {Explaining Explanations in {{AI}}},
  pages         = {279--288},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2019},
}

@Book{molnar2020interpretable,
  author        = {Molnar, Christoph},
  title         = {Interpretable Machine Learning},
  publisher     = {{Lulu. com}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Book{morgan2015counterfactuals,
  author        = {Morgan, Stephen L and Winship, Christopher},
  title         = {Counterfactuals and Causal Inference},
  publisher     = {{Cambridge University Press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2015},
}

@Article{mosteller1951experimental,
  author        = {Mosteller, Frederick and Nogee, Philip},
  title         = {An Experimental Measurement of Utility},
  number        = {5},
  pages         = {371--404},
  volume        = {59},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Political Economy},
  year          = {1951},
}

@InProceedings{mothilal2020explaining,
  author        = {Mothilal, Ramaravind K and Sharma, Amit and Tan, Chenhao},
  booktitle     = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  title         = {Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations},
  pages         = {607--617},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Book{murphy2012machine,
  author        = {Murphy, Kevin P},
  title         = {Machine Learning: A Probabilistic Perspective},
  publisher     = {{MIT press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2012},
}

@Book{murphy2012machine,
  author        = {Murphy, Kevin P},
  title         = {Machine Learning: {{A}} Probabilistic Perspective},
  publisher     = {{MIT press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2012},
}

@Book{murphy2022probabilistic,
  author        = {Murphy, Kevin P},
  title         = {Probabilistic {{Machine Learning}}: {{An}} Introduction},
  publisher     = {{MIT Press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2022},
}

@Article{nagel1995unraveling,
  author        = {Nagel, Rosemarie},
  title         = {Unraveling in Guessing Games: {{An}} Experimental Study},
  number        = {5},
  pages         = {1313--1326},
  volume        = {85},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The American Economic Review},
  year          = {1995},
}

@Unpublished{navarro-martinez2021bridging,
  author        = {Navarro-Martinez, Daniel and Wang, Xinghua},
  title         = {Bridging the Gap between the Lab and the Field: {{Dictator}} Games and Donations},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@InProceedings{nelson2015evaluating,
  author        = {Nelson, Kevin and Corbin, George and Anania, Mark and Kovacs, Matthew and Tobias, Jeremy and Blowers, Misty},
  booktitle     = {2015 {{IEEE Symposium}} on {{Computational Intelligence}} for {{Security}} and {{Defense Applications}} ({{CISDA}})},
  title         = {Evaluating Model Drift in Machine Learning Algorithms},
  pages         = {1--8},
  publisher     = {{IEEE}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2015},
}

@Book{nocedal2006numerical,
  author        = {Nocedal, Jorge and Wright, Stephen},
  title         = {Numerical Optimization},
  publisher     = {{Springer Science \& Business Media}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2006},
}

@Misc{oecd2021artificial,
  author        = {{OECD}},
  title         = {Artificial {{Intelligence}}, {{Machine Learning}} and {{Big Data}} in {{Finance}}: {{Opportunities}}, {{Challenges}} and {{Implications}} for {{Policy Makers}}},
  url           = {https://www.oecd.org/finance/financial-markets/Artificial-intelligence-machine-learning-big-data-in-finance.pdf},
  bdsk-url-1    = {https://www.oecd.org/finance/financial-markets/Artificial-intelligence-machine-learning-big-data-in-finance.pdf},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Online{oecdArtificialIntelligenceMachine2021,
  author        = {{OECD}},
  title         = {Artificial {{Intelligence}}, {{Machine Learning}} and {{Big Data}} in {{Finance}}: {{Opportunities}}, {{Challenges}} and {{Implications}} for {{Policy Makers}}},
  url           = {https://www.oecd.org/finance/financial-markets/Artificial-intelligence-machine-learning-big-data-in-finance.pdf},
  bdsk-url-1    = {https://www.oecd.org/finance/financial-markets/Artificial-intelligence-machine-learning-big-data-in-finance.pdf},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  publisher     = {{OECD}},
  year          = {2021},
}

@Book{oneil2016weapons,
  author        = {O'Neil, Cathy},
  title         = {Weapons of Math Destruction: {{How}} Big Data Increases Inequality and Threatens Democracy},
  publisher     = {{Crown}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2016},
}

@Article{pace1997sparse,
  author        = {Pace, R Kelley and Barry, Ronald},
  title         = {Sparse Spatial Autoregressions},
  number        = {3},
  pages         = {291--297},
  volume        = {33},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Statistics \& Probability Letters},
  year          = {1997},
}

@Unpublished{parr2018matrix,
  author        = {Parr, Terence and Howard, Jeremy},
  title         = {The Matrix Calculus You Need for Deep Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1802.01528},
  eprinttype    = {arxiv},
  year          = {2018},
}

@Unpublished{pawelczyk2021carla,
  author        = {Pawelczyk, Martin and Bielawski, Sascha and van den Heuvel, Johannes and Richter, Tobias and Kasneci, Gjergji},
  title         = {Carla: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2108.00783},
  eprinttype    = {arxiv},
  year          = {2021},
}

@Book{pearl2018book,
  author        = {Pearl, Judea and Mackenzie, Dana},
  title         = {The Book of Why: The New Science of Cause and Effect},
  publisher     = {{Basic books}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2018},
}

@Article{pearl2019seven,
  author        = {Pearl, Judea},
  title         = {The Seven Tools of Causal Inference, with Reflections on Machine Learning},
  number        = {3},
  pages         = {54--60},
  volume        = {62},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Communications of the ACM},
  year          = {2019},
}

@Article{pedregosa2011scikitlearn,
  author        = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  title         = {Scikit-Learn: {{Machine}} Learning in {{Python}}},
  pages         = {2825--2830},
  volume        = {12},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {the Journal of machine Learning research},
  year          = {2011},
}

@Book{perry2010economic,
  author        = {Perry, George L and Tobin, James},
  title         = {Economic {{Events}}, {{Ideas}}, and {{Policies}}: The 1960s and After},
  publisher     = {{Brookings Institution Press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2010},
}

@Article{pfaff2008var,
  author        = {Pfaff, Bernhard and others},
  title         = {{{VAR}}, {{SVAR}} and {{SVEC}} Models: {{Implementation}} within {{R}} Package Vars},
  number        = {4},
  pages         = {1--32},
  volume        = {27},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Statistical Software},
  year          = {2008},
}

@Book{pindyck2014microeconomics,
  author        = {Pindyck, Robert S and Rubinfeld, Daniel L},
  title         = {Microeconomics},
  publisher     = {{Pearson Education}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2014},
}

@Article{pope2011numbers,
  author        = {Pope, Devin and Simonsohn, Uri},
  title         = {Round Numbers as Goals: {{Evidence}} from Baseball, {{SAT}} Takers, and the Lab},
  number        = {1},
  pages         = {71--79},
  volume        = {22},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Psychological science},
  year          = {2011},
}

@InProceedings{poyiadzi2020face,
  author        = {Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter},
  booktitle     = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  title         = {{{FACE}}: {{Feasible}} and Actionable Counterfactual Explanations},
  pages         = {344--350},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Article{qu2015estimating,
  author        = {Qu, Xi and Lee, Lung-fei},
  title         = {Estimating a Spatial Autoregressive Model with an Endogenous Spatial Weight Matrix},
  number        = {2},
  pages         = {209--232},
  volume        = {184},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of Econometrics},
  year          = {2015},
}

@Article{rabanser2019failing,
  author        = {Rabanser, Stephan and G{\"u}nnemann, Stephan and Lipton, Zachary},
  title         = {Failing Loudly: {{An}} Empirical Study of Methods for Detecting Dataset Shift},
  volume        = {32},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2019},
}

@Unpublished{raghunathan2019adversarial,
  author        = {Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John C and Liang, Percy},
  title         = {Adversarial Training Can Hurt Generalization},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1906.06032},
  eprinttype    = {arxiv},
  year          = {2019},
}

@Unpublished{raj2017taming,
  author        = {Raj, Vishnu and Kalyani, Sheetal},
  title         = {Taming Non-Stationary Bandits: {{A Bayesian}} Approach},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1707.09727},
  eprinttype    = {arxiv},
  year          = {2017},
}

@InProceedings{rasmussen2003gaussian,
  author        = {Rasmussen, Carl Edward},
  booktitle     = {Summer School on Machine Learning},
  title         = {Gaussian Processes in Machine Learning},
  pages         = {63--71},
  publisher     = {{Springer}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2003},
}

@InProceedings{ribeiro2016why,
  author        = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle     = {Proceedings of the 22nd {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  title         = {"{{Why}} Should i Trust You?" {{Explaining}} the Predictions of Any Classifier},
  pages         = {1135--1144},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2016},
}

@Article{romer1989does,
  author        = {Romer, Christina D and Romer, David H},
  title         = {Does Monetary Policy Matter? {{A}} New Test in the Spirit of {{Friedman}} and {{Schwartz}}},
  pages         = {121--170},
  volume        = {4},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {NBER macroeconomics annual},
  year          = {1989},
}

@Article{rudin2019stop,
  author        = {Rudin, Cynthia},
  title         = {Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead},
  number        = {5},
  pages         = {206--215},
  volume        = {1},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Nature Machine Intelligence},
  year          = {2019},
}

@Article{sacerdote2001peer,
  author        = {Sacerdote, Bruce},
  title         = {Peer Effects with Random Assignment: {{Results}} for {{Dartmouth}} Roommates},
  number        = {2},
  pages         = {681--704},
  volume        = {116},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The Quarterly journal of economics},
  year          = {2001},
}

@Article{sadinle2019least,
  author        = {Sadinle, Mauricio and Lei, Jing and Wasserman, Larry},
  title         = {Least Ambiguous Set-Valued Classifiers with Bounded Error Levels},
  number        = {525},
  pages         = {223--234},
  volume        = {114},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  file          = {:/Users/FA31DU/Zotero/storage/YXQ8N76A/Sadinle et al. - 2019 - Least ambiguous set-valued classifiers with bounde.pdf:;:/Users/FA31DU/Zotero/storage/ZHB56F3V/01621459.2017.html:},
  journal       = {Journal of the American Statistical Association},
  publisher     = {{Taylor \& Francis}},
  year          = {2019},
}

@InProceedings{satopaa2011finding,
  author        = {Satopaa, Ville and Albrecht, Jeannie and Irwin, David and Raghavan, Barath},
  booktitle     = {2011 31st International Conference on Distributed Computing Systems Workshops},
  title         = {Finding a" Kneedle" in a Haystack: {{Detecting}} Knee Points in System Behavior},
  pages         = {166--171},
  publisher     = {{IEEE}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2011},
}

@InProceedings{schut2021generating,
  author        = {Schut, Lisa and Key, Oscar and Mc Grath, Rory and Costabello, Luca and Sacaleanu, Bogdan and Gal, Yarin and others},
  booktitle     = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  title         = {Generating {{Interpretable Counterfactual Explanations By Implicit Minimisation}} of {{Epistemic}} and {{Aleatoric Uncertainties}}},
  pages         = {1756--1764},
  publisher     = {{PMLR}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2021},
}

@Book{schutze2008introduction,
  author        = {Sch{\"u}tze, Hinrich and Manning, Christopher D and Raghavan, Prabhakar},
  title         = {Introduction to Information Retrieval},
  publisher     = {{Cambridge University Press Cambridge}},
  volume        = {39},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2008},
}

@Article{shafir1993reasonbased,
  author        = {Shafir, Eldar and Simonson, Itamar and Tversky, Amos},
  title         = {Reason-Based Choice},
  number        = {1-2},
  pages         = {11--36},
  volume        = {49},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Cognition},
  year          = {1993},
}

@Article{simonson1989choice,
  author        = {Simonson, Itamar},
  title         = {Choice Based on Reasons: {{The}} Case of Attraction and Compromise Effects},
  number        = {2},
  pages         = {158--174},
  volume        = {16},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of consumer research},
  year          = {1989},
}

@Article{sims1986are,
  author        = {Sims, Christopher A and others},
  title         = {Are Forecasting Models Usable for Policy Analysis?},
  issue         = {Win},
  pages         = {2--16},
  volume        = {10},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Quarterly Review},
  year          = {1986},
}

@InProceedings{slack2020fooling,
  author        = {Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle     = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  title         = {Fooling Lime and Shap: {{Adversarial}} Attacks on Post Hoc Explanation Methods},
  pages         = {180--186},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2020},
}

@Article{slack2021counterfactual,
  author        = {Slack, Dylan and Hilgard, Anna and Lakkaraju, Himabindu and Singh, Sameer},
  title         = {Counterfactual Explanations Can Be Manipulated},
  volume        = {34},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2021},
}

@Article{slovic1974who,
  author        = {Slovic, Paul and Tversky, Amos},
  title         = {Who Accepts {{Savage}}'s Axiom?},
  number        = {6},
  pages         = {368--373},
  volume        = {19},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Behavioral science},
  year          = {1974},
}

@Unpublished{spooner2021counterfactual,
  author        = {Spooner, Thomas and Dervovic, Danial and Long, Jason and Shepard, Jon and Chen, Jiahao and Magazzeni, Daniele},
  title         = {Counterfactual {{Explanations}} for {{Arbitrary Regression Models}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2106.15212},
  eprinttype    = {arxiv},
  shortjournal  = {arXiv preprint arXiv:2106.15212},
  year          = {2021},
}

@Article{srivastava2014dropout,
  author        = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  title         = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  number        = {1},
  pages         = {1929--1958},
  volume        = {15},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The journal of machine learning research},
  year          = {2014},
}

@Unpublished{stanton2022bayesian,
  author        = {Stanton, Samuel and Maddox, Wesley and Wilson, Andrew Gordon},
  title         = {Bayesian {{Optimization}} with {{Conformal Coverage Guarantees}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2210.12496},
  eprinttype    = {arxiv},
  file          = {:/Users/FA31DU/Zotero/storage/XFGZAB9J/Stanton et al. - 2022 - Bayesian Optimization with Conformal Coverage Guar.pdf:;:/Users/FA31DU/Zotero/storage/RPWYDPVW/2210.html:},
  year          = {2022},
}

@Article{sturm2014simple,
  author        = {Sturm, Bob L},
  title         = {A Simple Method to Determine If a Music Information Retrieval System Is a ``Horse''},
  number        = {6},
  pages         = {1636--1644},
  volume        = {16},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {IEEE Transactions on Multimedia},
  year          = {2014},
}

@Article{sunstein2003libertarian,
  author        = {Sunstein, Cass R and Thaler, Richard H},
  title         = {Libertarian Paternalism Is Not an Oxymoron},
  pages         = {1159--1202},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {The University of Chicago Law Review},
  year          = {2003},
}

@Book{sutton2018reinforcement,
  author        = {Sutton, Richard S and Barto, Andrew G},
  title         = {Reinforcement Learning: {{An}} Introduction},
  publisher     = {{MIT press}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2018},
}

@Unpublished{szegedy2013intriguing,
  author        = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  title         = {Intriguing Properties of Neural Networks},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1312.6199},
  eprinttype    = {arxiv},
  year          = {2013},
}

@Article{thaler1981empirical,
  author        = {Thaler, Richard},
  title         = {Some Empirical Evidence on Dynamic Inconsistency},
  number        = {3},
  pages         = {201--207},
  volume        = {8},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Economics letters},
  year          = {1981},
}

@Article{thaler2004more,
  author        = {Thaler, Richard H and Benartzi, Shlomo},
  title         = {Save More Tomorrow{\texttrademark}: {{Using}} Behavioral Economics to Increase Employee Saving},
  number        = {S1},
  pages         = {S164--S187},
  volume        = {112},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of political Economy},
  year          = {2004},
}

@Article{tversky1981framing,
  author        = {Tversky, Amos and Kahneman, Daniel},
  title         = {The Framing of Decisions and the Psychology of Choice},
  number        = {4481},
  pages         = {453--458},
  volume        = {211},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Science (New York, N.Y.)},
  shortjournal  = {science},
  year          = {1981},
}

@Article{ungemach2011how,
  author        = {Ungemach, Christoph and Stewart, Neil and Reimers, Stian},
  title         = {How Incidental Values from the Environment Affect Decisions about Money, Risk, and Delay},
  number        = {2},
  pages         = {253--260},
  volume        = {22},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Psychological Science},
  year          = {2011},
}

@Unpublished{upadhyay2021robust,
  author        = {Upadhyay, Sohini and Joshi, Shalmali and Lakkaraju, Himabindu},
  title         = {Towards {{Robust}} and {{Reliable Algorithmic Recourse}}},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2102.13620},
  eprinttype    = {arxiv},
  year          = {2021},
}

@InProceedings{ustun2019actionable,
  author        = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
  booktitle     = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  title         = {Actionable Recourse in Linear Classification},
  pages         = {10--19},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2019},
}

@Article{vanboven2000egocentric,
  author        = {Van Boven, Leaf and Dunning, David and Loewenstein, George},
  title         = {Egocentric Empathy Gaps between Owners and Buyers: Misperceptions of the Endowment Effect.},
  number        = {1},
  pages         = {66},
  volume        = {79},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of personality and social psychology},
  year          = {2000},
}

@Book{varshney2022trustworthy,
  author        = {Varshney, Kush R.},
  title         = {Trustworthy {{Machine Learning}}},
  publisher     = {{Independently Published}},
  address       = {{Chappaqua, NY, USA}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2022},
}

@Unpublished{verma2020counterfactual,
  author        = {Verma, Sahil and Dickerson, John and Hines, Keegan},
  title         = {Counterfactual Explanations for Machine Learning: {{A}} Review},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2010.10596},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Article{verstyuk2020modeling,
  author        = {Verstyuk, Sergiy},
  title         = {Modeling Multivariate Time Series in Economics: {{From}} Auto-Regressions to Recurrent Neural Networks},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Available at SSRN 3589337},
  year          = {2020},
}

@Article{wachter2017counterfactual,
  author        = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  title         = {Counterfactual Explanations without Opening the Black Box: {{Automated}} Decisions and the {{GDPR}}},
  pages         = {841},
  volume        = {31},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Harv. JL \& Tech.},
  year          = {2017},
}

@Article{wang2018optimal,
  author        = {Wang, HaiYing and Zhu, Rong and Ma, Ping},
  title         = {Optimal Subsampling for Large Sample Logistic Regression},
  number        = {522},
  pages         = {829--844},
  volume        = {113},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Journal of the American Statistical Association},
  year          = {2018},
}

@Book{wasserman2006all,
  author        = {Wasserman, Larry},
  title         = {All of Nonparametric Statistics},
  publisher     = {{Springer Science \& Business Media}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2006},
}

@Book{wasserman2013all,
  author        = {Wasserman, Larry},
  title         = {All of Statistics: A Concise Course in Statistical Inference},
  publisher     = {{Springer Science \& Business Media}},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  year          = {2013},
}

@Article{widmer1996learning,
  author        = {Widmer, Gerhard and Kubat, Miroslav},
  title         = {Learning in the Presence of Concept Drift and Hidden Contexts},
  number        = {1},
  pages         = {69--101},
  volume        = {23},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Machine learning},
  year          = {1996},
}

@Unpublished{wilson2020case,
  author        = {Wilson, Andrew Gordon},
  title         = {The Case for {{Bayesian}} Deep Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {2001.10995},
  eprinttype    = {arxiv},
  year          = {2020},
}

@Article{witten2009penalized,
  author        = {Witten, Daniela M and Tibshirani, Robert and Hastie, Trevor},
  title         = {A Penalized Matrix Decomposition, with Applications to Sparse Principal Components and Canonical Correlation Analysis},
  number        = {3},
  pages         = {515--534},
  volume        = {10},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Biostatistics (Oxford, England)},
  shortjournal  = {Biostatistics},
  year          = {2009},
}

@Article{xu2020epidemiological,
  author        = {Xu, Bo and Gutierrez, Bernardo and Mekaru, Sumiko and Sewalk, Kara and Goodwin, Lauren and Loskill, Alyssa and Cohn, Emily and Hswen, Yulin and Hill, Sarah C. and Cobo, Maria M and Zarebski, Alexander and Li, Sabrina and Wu, Chieh-Hsi and Hulland, Erin and Morgan, Julia and Wang, Lin and O'Brien, Katelynn and Scarpino, Samuel V. and Brownstein, John S. and Pybus, Oliver G. and Pigott, David M. and Kraemer, Moritz U. G.},
  title         = {Epidemiological Data from the {{COVID-19}} Outbreak, Real-Time Case Information},
  doi           = {doi.org/10.1038/s41597-020-0448-0},
  number        = {106},
  volume        = {7},
  bdsk-url-1    = {https://doi.org/10.1038/s41597-020-0448-0},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Scientific Data},
  year          = {2020},
}

@Article{yeh2009comparisons,
  author        = {Yeh, I-Cheng and Lien, Che-hui},
  title         = {The Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients},
  number        = {2},
  pages         = {2473--2480},
  volume        = {36},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Expert systems with applications},
  year          = {2009},
}

@Article{zhang1998forecasting,
  author        = {Zhang, Guoqiang and Patuwo, B Eddy and Hu, Michael Y},
  title         = {Forecasting with Artificial Neural Networks:: {{The}} State of the Art},
  number        = {1},
  pages         = {35--62},
  volume        = {14},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {International journal of forecasting},
  year          = {1998},
}

@Article{zhang2003time,
  author        = {Zhang, G Peter},
  title         = {Time Series Forecasting Using a Hybrid {{ARIMA}} and Neural Network Model},
  pages         = {159--175},
  volume        = {50},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {Neurocomputing},
  year          = {2003},
}

@Unpublished{zheng2018dags,
  author        = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric P},
  title         = {Dags with No Tears: {{Continuous}} Optimization for Structure Learning},
  archiveprefix = {arXiv},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  eprint        = {1803.01422},
  eprinttype    = {arxiv},
  year          = {2018},
}

@Article{zhu2015optimal,
  author        = {Zhu, Rong and Ma, Ping and Mahoney, Michael W and Yu, Bin},
  title         = {Optimal Subsampling Approaches for Large Sample Linear Regression},
  pages         = {arXiv--1509},
  date-added    = {2022-12-13 12:58:01 +0100},
  date-modified = {2022-12-13 12:58:01 +0100},
  journal       = {arXiv},
  year          = {2015},
}

@Article{barber2021predictive,
  author    = {Barber, Rina Foygel and Candès, Emmanuel J. and Ramdas, Aaditya and Tibshirani, Ryan J.},
  title     = {Predictive inference with the jackknife+},
  doi       = {10.1214/20-AOS1965},
  issn      = {0090-5364, 2168-8966},
  number    = {1},
  pages     = {486--507},
  urldate   = {2022-12-13},
  volume    = {49},
  abstract  = {This paper introduces the jackknife+, which is a novel method for constructing predictive confidence intervals. Whereas the jackknife outputs an interval centered at the predicted response of a test point, with the width of the interval determined by the quantiles of leave-one-out residuals, the jackknife+ also uses the leave-one-out predictions at the test point to account for the variability in the fitted regression function. Assuming exchangeable training samples, we prove that this crucial modification permits rigorous coverage guarantees regardless of the distribution of the data points, for any algorithm that treats the training points symmetrically. Such guarantees are not possible for the original jackknife and we demonstrate examples where the coverage rate may actually vanish. Our theoretical and empirical analysis reveals that the jackknife and the jackknife+ intervals achieve nearly exact coverage and have similar lengths whenever the fitting algorithm obeys some form of stability. Further, we extend the jackknife+ to \$K\$-fold cross validation and similarly establish rigorous coverage properties. Our methods are related to cross-conformal prediction proposed by Vovk (Ann. Math. Artif. Intell. 74 (2015) 9–28) and we discuss connections.},
  file      = {:Barber2021 - Predictive Inference with the Jackknife+.pdf:PDF},
  journal   = {The Annals of Statistics},
  keywords  = {62F40, 62G08, 62G09, conformal inference, cross-validation, distribution-free, jackknife, leave-one-out, stability},
  month     = feb,
  publisher = {Institute of Mathematical Statistics},
  year      = {2021},
}

@TechReport{chouldechova2018frontiers,
  author        = {Chouldechova, Alexandra and Roth, Aaron},
  title         = {The {Frontiers} of {Fairness} in {Machine} {Learning}},
  doi           = {10.48550/arXiv.1810.08810},
  eprint        = {1810.08810},
  note          = {arXiv:1810.08810 [cs, stat] type: article},
  abstract      = {The last few years have seen an explosion of academic and popular interest in algorithmic fairness. Despite this interest and the volume and velocity of work that has been produced recently, the fundamental science of fairness in machine learning is still in a nascent state. In March 2018, we convened a group of experts as part of a CCC visioning workshop to assess the state of the field, and distill the most promising research directions going forward. This report summarizes the findings of that workshop. Along the way, it surveys recent theoretical work in the field and points towards promising directions for research.},
  archiveprefix = {arxiv},
  file          = {:chouldechova2018frontiers - The Frontiers of Fairness in Machine Learning.pdf:PDF},
  keywords      = {Computer Science - Machine Learning, Computer Science - Data Structures and Algorithms, Computer Science - Computer Science and Game Theory, Statistics - Machine Learning},
  month         = oct,
  school        = {arXiv},
  year          = {2018},
}

@Article{pawelczyk2022probabilistically,
  author     = {Pawelczyk, Martin and Datta, Teresa and van-den-Heuvel, Johannes and Kasneci, Gjergji and Lakkaraju, Himabindu},
  title      = {Probabilistically {Robust} {Recourse}: {Navigating} the {Trade}-offs between {Costs} and {Robustness} in {Algorithmic} {Recourse}},
  file       = {:pawelczyk2022probabilistically - Probabilistically Robust Recourse_ Navigating the Trade Offs between Costs and Robustness in Algorithmic Recourse.pdf:PDF},
  journal    = {arXiv preprint arXiv:2203.06768},
  shorttitle = {Probabilistically {Robust} {Recourse}},
  year       = {2022},
}

@InProceedings{stutz2022learning,
  author   = {Stutz, David and Dvijotham, Krishnamurthy Dj and Cemgil, Ali Taylan and Doucet, Arnaud},
  title    = {Learning {Optimal} {Conformal} {Classifiers}},
  language = {en},
  url      = {https://openreview.net/forum?id=t8O-4LKFVx},
  urldate  = {2023-02-13},
  abstract = {Modern deep learning based classifiers show very high accuracy on test data but this does not provide sufficient guarantees for safe deployment, especially in high-stake AI applications such as medical diagnosis. Usually, predictions are obtained without a reliable uncertainty estimate or a formal guarantee. Conformal prediction (CP) addresses these issues by using the classifier's predictions, e.g., its probability estimates, to predict confidence sets containing the true class with a user-specified probability. However, using CP as a separate processing step after training prevents the underlying model from adapting to the prediction of confidence sets. Thus, this paper explores strategies to differentiate through CP during training with the goal of training model with the conformal wrapper end-to-end. In our approach, conformal training (ConfTr), we specifically "simulate" conformalization on mini-batches during training. Compared to standard training, ConfTr reduces the average confidence set size (inefficiency) of state-of-the-art CP methods applied after training. Moreover, it allows to "shape" the confidence sets predicted at test time, which is difficult for standard CP. On experiments with several datasets, we show ConfTr can influence how inefficiency is distributed across classes, or guide the composition of confidence sets in terms of the included classes, while retaining the guarantees offered by CP.},
  file     = {:stutz2022learning - Learning Optimal Conformal Classifiers.pdf:PDF},
  month    = may,
  year     = {2022},
}

@InProceedings{grathwohl2020your,
  author   = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Joern-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  title    = {Your classifier is secretly an energy based model and you should treat it like one},
  language = {en},
  url      = {https://openreview.net/forum?id=Hkxzx0NtDB},
  urldate  = {2023-02-13},
  abstract = {We propose to reinterpret a standard discriminative classifier of p(y{\textbar}x) as an energy based model for the joint distribution p(x, y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x{\textbar}y). Within this framework, standard discriminative architectures may be used and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, and out-of-distribution detection while also enabling our models to generate samples rivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and present an approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-art in both generative and discriminative learning within one hybrid model.},
  file     = {:grathwohl2020your - Your Classifier Is Secretly an Energy Based Model and You Should Treat It like One.pdf:PDF},
  month    = mar,
  year     = {2020},
}

@Book{murphy2023probabilistic,
  author     = {Murphy, Kevin P.},
  date       = {2023},
  title      = {Probabilistic machine learning: {Advanced} topics},
  publisher  = {MIT Press},
  shorttitle = {Probabilistic machine learning},
}

@TechReport{artelt2021evaluating,
  author      = {Artelt, André and Vaquet, Valerie and Velioglu, Riza and Hinder, Fabian and Brinkrolf, Johannes and Schilling, Malte and Hammer, Barbara},
  date        = {2021-07},
  institution = {arXiv},
  title       = {Evaluating {Robustness} of {Counterfactual} {Explanations}},
  note        = {arXiv:2103.02354 [cs] type: article},
  url         = {http://arxiv.org/abs/2103.02354},
  urldate     = {2023-03-24},
  abstract    = {Transparency is a fundamental requirement for decision making systems when these should be deployed in the real world. It is usually achieved by providing explanations of the system's behavior. A prominent and intuitive type of explanations are counterfactual explanations. Counterfactual explanations explain a behavior to the user by proposing actions -- as changes to the input -- that would cause a different (specified) behavior of the system. However, such explanation methods can be unstable with respect to small changes to the input -- i.e. even a small change in the input can lead to huge or arbitrary changes in the output and of the explanation. This could be problematic for counterfactual explanations, as two similar individuals might get very different explanations. Even worse, if the recommended actions differ considerably in their complexity, one would consider such unstable (counterfactual) explanations as individually unfair. In this work, we formally and empirically study the robustness of counterfactual explanations in general, as well as under different models and different kinds of perturbations. Furthermore, we propose that plausible counterfactual explanations can be used instead of closest counterfactual explanations to improve the robustness and consequently the individual fairness of counterfactual explanations.},
  annotation  = {Comment: Rewrite paper to make things more clear; Remove one theorem \& corollary due to buggy proof},
  file        = {:artelt2021evaluating - Evaluating Robustness of Counterfactual Explanations.pdf:PDF},
  keywords    = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@Article{guidotti2022counterfactual,
  author       = {Guidotti, Riccardo},
  date         = {2022-04},
  journaltitle = {Data Mining and Knowledge Discovery},
  title        = {Counterfactual explanations and how to find them: literature review and benchmarking},
  doi          = {10.1007/s10618-022-00831-6},
  issn         = {1573-756X},
  language     = {en},
  url          = {https://doi.org/10.1007/s10618-022-00831-6},
  urldate      = {2023-03-24},
  abstract     = {Interpretable machine learning aims at unveiling the reasons behind predictions returned by uninterpretable classifiers. One of the most valuable types of explanation consists of counterfactuals. A counterfactual explanation reveals what should have been different in an instance to observe a diverse outcome. For instance, a bank customer asks for a loan that is rejected. The counterfactual explanation consists of what should have been different for the customer in order to have the loan accepted. Recently, there has been an explosion of proposals for counterfactual explainers. The aim of this work is to survey the most recent explainers returning counterfactual explanations. We categorize explainers based on the approach adopted to return the counterfactuals, and we label them according to characteristics of the method and properties of the counterfactuals returned. In addition, we visually compare the explanations, and we report quantitative benchmarking assessing minimality, actionability, stability, diversity, discriminative power, and running time. The results make evident that the current state of the art does not provide a counterfactual explainer able to guarantee all these properties simultaneously.},
  file         = {Full Text PDF:https\://link.springer.com/content/pdf/10.1007%2Fs10618-022-00831-6.pdf:application/pdf},
  keywords     = {Explainable AI, Counterfactual explanations, Contrastive explanations, Interpretable machine learning},
  shorttitle   = {Counterfactual explanations and how to find them},
}

@TechReport{mahajan2020preserving,
  author      = {Mahajan, Divyat and Tan, Chenhao and Sharma, Amit},
  date        = {2020-06},
  institution = {arXiv},
  title       = {Preserving {Causal} {Constraints} in {Counterfactual} {Explanations} for {Machine} {Learning} {Classifiers}},
  doi         = {10.48550/arXiv.1912.03277},
  note        = {arXiv:1912.03277 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1912.03277},
  urldate     = {2023-03-24},
  abstract    = {To construct interpretable explanations that are consistent with the original ML model, counterfactual examples---showing how the model's output changes with small perturbations to the input---have been proposed. This paper extends the work in counterfactual explanations by addressing the challenge of feasibility of such examples. For explanations of ML models in critical domains such as healthcare and finance, counterfactual examples are useful for an end-user only to the extent that perturbation of feature inputs is feasible in the real world. We formulate the problem of feasibility as preserving causal relationships among input features and present a method that uses (partial) structural causal models to generate actionable counterfactuals. When feasibility constraints cannot be easily expressed, we consider an alternative mechanism where people can label generated CF examples on feasibility: whether it is feasible to intervene and realize the candidate CF example from the original input. To learn from this labelled feasibility data, we propose a modified variational auto encoder loss for generating CF examples that optimizes for feasibility as people interact with its output. Our experiments on Bayesian networks and the widely used ''Adult-Income'' dataset show that our proposed methods can generate counterfactual explanations that better satisfy feasibility constraints than existing methods.. Code repository can be accessed here: {\textbackslash}textit\{https://github.com/divyat09/cf-feasibility\}},
  annotation  = {Comment: 2019 NeurIPS Workshop on Do the right thing: Machine learning and Causal Inference for improved decision making},
  file        = {:mahajan2020preserving - Preserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers.pdf:PDF},
  keywords    = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
}

@TechReport{antoran2023sampling,
  author      = {Antorán, Javier and Padhy, Shreyas and Barbano, Riccardo and Nalisnick, Eric and Janz, David and Hernández-Lobato, José Miguel},
  date        = {2023-03},
  institution = {arXiv},
  title       = {Sampling-based inference for large linear models, with application to linearised {Laplace}},
  note        = {arXiv:2210.04994 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/2210.04994},
  urldate     = {2023-03-25},
  abstract    = {Large-scale linear models are ubiquitous throughout machine learning, with contemporary application as surrogate models for neural network uncertainty quantification; that is, the linearised Laplace method. Alas, the computational cost associated with Bayesian linear models constrains this method's application to small networks, small output spaces and small datasets. We address this limitation by introducing a scalable sample-based Bayesian inference method for conjugate Gaussian multi-output linear models, together with a matching method for hyperparameter (regularisation) selection. Furthermore, we use a classic feature normalisation method (the g-prior) to resolve a previously highlighted pathology of the linearised Laplace method. Together, these contributions allow us to perform linearised neural network inference with ResNet-18 on CIFAR100 (11M parameters, 100 outputs x 50k datapoints), with ResNet-50 on Imagenet (50M parameters, 1000 outputs x 1.2M datapoints) and with a U-Net on a high-resolution tomographic reconstruction task (2M parameters, 251k output{\textasciitilde}dimensions).},
  annotation  = {Comment: Published at ICLR 2023. This latest Arxiv version is extended with a demonstration of the proposed methods on the Imagenet dataset},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2210.04994.pdf:application/pdf},
  keywords    = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@Misc{altmeyer2022conformal,
  author   = {Altmeyer, Patrick},
  date     = {2022-10},
  title    = {{Conformal} {Prediction} in {Julia}},
  language = {en},
  url      = {https://www.paltmeyer.com/blog/posts/conformal-prediction/},
  urldate  = {2023-03-27},
  abstract = {A (very) gentle introduction to Conformal Prediction in Julia using my new package ConformalPrediction.jl.},
}

@InProceedings{welling2011bayesian,
  author     = {Welling, M. and Teh, Y.},
  date       = {2011-06},
  title      = {Bayesian {Learning} via {Stochastic} {Gradient} {Langevin} {Dynamics}},
  url        = {https://www.semanticscholar.org/paper/Bayesian-Learning-via-Stochastic-Gradient-Langevin-Welling-Teh/aeed631d6a84100b5e9a021ec1914095c66de415},
  urldate    = {2023-05-15},
  abstract   = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a "sampling threshold" and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients.},
  annotation = {[TLDR] This paper proposes a new framework for learning from large scale datasets based on iterative learning from small mini-batches by adding the right amount of noise to a standard stochastic gradient optimization algorithm and shows that the iterates will converge to samples from the true posterior distribution as the authors anneal the stepsize.},
  file       = {:welling_bayesian_2011 - Bayesian Learning Via Stochastic Gradient Langevin Dynamics.html:URL;:welling2011bayesian - Bayesian Learning Via Stochastic Gradient Langevin Dynamics.pdf:PDF},
}

@Article{gill2010circular,
  author       = {Gill, Jeff and Hangartner, Dominik},
  date         = {2010},
  journaltitle = {Political Analysis},
  title        = {Circular {Data} in {Political} {Science} and {How} to {Handle} {It}},
  doi          = {10.1093/pan/mpq009},
  issn         = {1047-1987, 1476-4989},
  language     = {en},
  number       = {3},
  pages        = {316--336},
  url          = {https://www.cambridge.org/core/journals/political-analysis/article/circular-data-in-political-science-and-how-to-handle-it/6DF2D9DA60C455E6A48FFB0FF011F747},
  urldate      = {2023-05-15},
  volume       = {18},
  abstract     = {There has been no attention to circular (purely cyclical) data in political science research. We show that such data exist and are mishandled by models that do not take into account the inherently recycling nature of some phenomenon. Clock and calendar effects are the obvious cases, but directional data are observed as well. We describe a standard maximum likelihood regression modeling framework based on the von Mises distribution, then develop a general Bayesian regression procedure for the first time, providing an easy-to-use Metropolis-Hastings sampler for this approach. Applications include a chronographic analysis of U.S. domestic terrorism and directional party preferences in a two-dimensional ideological space for German Bundestag elections. The results demonstrate the importance of circular models to handle periodic and directional data in political science.},
  file         = {Full Text PDF:https\://www.cambridge.org/core/services/aop-cambridge-core/content/view/6DF2D9DA60C455E6A48FFB0FF011F747/S1047198700012493a.pdf/div-class-title-circular-data-in-political-science-and-how-to-handle-it-div.pdf:application/pdf},
  publisher    = {Cambridge University Press},
}

@InProceedings{liu2023goggle,
  author     = {Liu, Tennison and Qian, Zhaozhi and Berrevoets, Jeroen and Schaar, Mihaela van der},
  date       = {2023-02},
  title      = {{GOGGLE}: {Generative} {Modelling} for {Tabular} {Data} by {Learning} {Relational} {Structure}},
  language   = {en},
  url        = {https://openreview.net/forum?id=fPVRcJqspu},
  urldate    = {2023-05-15},
  abstract   = {Deep generative models learn highly complex and non-linear representations to generate realistic synthetic data. While they have achieved notable success in computer vision and natural language processing, similar advances have been less demonstrable in the tabular domain. This is partially because generative modelling of tabular data entails a particular set of challenges, including heterogeneous relationships, limited number of samples, and difficulties in incorporating prior knowledge. Additionally, unlike their counterparts in image and sequence domain, deep generative models for tabular data almost exclusively employ fully-connected layers, which encode weak inductive biases about relationships between inputs. Real-world data generating processes can often be represented using relational structures, which encode sparse, heterogeneous relationships between variables. In this work, we learn and exploit relational structure underlying tabular data to better model variable dependence, and as a natural means to introduce regularization on relationships and include prior knowledge. Specifically, we introduce GOGGLE, an end-to-end message passing scheme that jointly learns the relational structure and corresponding functional relationships as the basis of generating synthetic samples. Using real-world datasets, we provide empirical evidence that the proposed method is effective in generating realistic synthetic data and exploiting domain knowledge for downstream tasks.},
  file       = {Full Text PDF:https\://openreview.net/pdf?id=fPVRcJqspu:application/pdf},
  shorttitle = {{GOGGLE}},
}

@TechReport{du2020implicit,
  author      = {Du, Yilun and Mordatch, Igor},
  date        = {2020-06},
  institution = {arXiv},
  title       = {Implicit {Generation} and {Generalization} in {Energy}-{Based} {Models}},
  doi         = {10.48550/arXiv.1903.08689},
  note        = {arXiv:1903.08689 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1903.08689},
  urldate     = {2023-05-16},
  abstract    = {Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1903.08689.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
}

@InProceedings{krizhevsky2009learning,
  author     = {Krizhevsky, A.},
  date       = {2009},
  title      = {Learning {Multiple} {Layers} of {Features} from {Tiny} {Images}},
  url        = {https://www.semanticscholar.org/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086},
  urldate    = {2023-06-21},
  abstract   = {Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.},
  annotation = {[TLDR] It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network.},
  file       = {Semantic Scholar Link:https\://www.semanticscholar.org/paper/Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky/5d90f06bb70a0a3dced62413346235c02b1aa086:text/html;Full Text PDF:http\://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf:application/pdf},
}

@Misc{becker1996adult,
  author    = {Barry Becker, Ronny Kohavi},
  date      = {1996},
  title     = {Adult},
  doi       = {10.24432/C5XW20},
  note      = {Type: dataset},
  url       = {https://archive.ics.uci.edu/dataset/2},
  urldate   = {2023-06-21},
  publisher = {UCI Machine Learning Repository},
}

@InProceedings{tolomei2017interpretable,
  author     = {Tolomei, Gabriele and Silvestri, Fabrizio and Haines, Andrew and Lalmas, Mounia},
  booktitle  = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
  date       = {2017-08},
  title      = {Interpretable {Predictions} of {Tree}-based {Ensembles} via {Actionable} {Feature} {Tweaking}},
  doi        = {10.1145/3097983.3098039},
  note       = {arXiv:1706.06691 [stat]},
  pages      = {465--474},
  url        = {http://arxiv.org/abs/1706.06691},
  urldate    = {2023-06-21},
  abstract   = {Machine-learned models are often described as "black boxes". In many real-world applications however, models may have to sacrifice predictive power in favour of human-interpretability. When this is the case, feature engineering becomes a crucial task, which requires significant and time-consuming human effort. Whilst some features are inherently static, representing properties that cannot be influenced (e.g., the age of an individual), others capture characteristics that could be adjusted (e.g., the daily amount of carbohydrates taken). Nonetheless, once a model is learned from the data, each prediction it makes on new instances is irreversible - assuming every instance to be a static point located in the chosen feature space. There are many circumstances however where it is important to understand (i) why a model outputs a certain prediction on a given instance, (ii) which adjustable features of that instance should be modified, and finally (iii) how to alter such a prediction when the mutated instance is input back to the model. In this paper, we present a technique that exploits the internals of a tree-based ensemble classifier to offer recommendations for transforming true negative instances into positively predicted ones. We demonstrate the validity of our approach using an online advertising application. First, we design a Random Forest classifier that effectively separates between two types of ads: low (negative) and high (positive) quality ads (instances). Then, we introduce an algorithm that provides recommendations that aim to transform a low quality ad (negative instance) into a high quality one (positive instance). Finally, we evaluate our approach on a subset of the active inventory of a large ad network, Yahoo Gemini.},
  annotation = {Comment: 10 pages, KDD 2017},
  file       = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1706.06691.pdf:application/pdf},
  keywords   = {Statistics - Machine Learning, 68T01, I.2.0, I.5.1},
}

@TechReport{dandl2023counterfactuals,
  author      = {Dandl, Susanne and Hofheinz, Andreas and Binder, Martin and Bischl, Bernd and Casalicchio, Giuseppe},
  date        = {2023-04},
  institution = {arXiv},
  title       = {counterfactuals: {An} {R} {Package} for {Counterfactual} {Explanation} {Methods}},
  note        = {arXiv:2304.06569 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/2304.06569},
  urldate     = {2023-06-21},
  abstract    = {Counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. Despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. In this work, we introduce the counterfactuals R package, which provides a modular and unified R6-based interface for counterfactual explanation methods. We implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. We explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. In addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2304.06569.pdf:application/pdf},
  keywords    = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Computation},
  shorttitle  = {counterfactuals},
}

@TechReport{laugel2017inversea,
  author      = {Laugel, Thibault and Lesot, Marie-Jeanne and Marsala, Christophe and Renard, Xavier and Detyniecki, Marcin},
  date        = {2017-12},
  institution = {arXiv},
  title       = {Inverse {Classification} for {Comparison}-based {Interpretability} in {Machine} {Learning}},
  doi         = {10.48550/arXiv.1712.08443},
  note        = {arXiv:1712.08443 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1712.08443},
  urldate     = {2023-06-21},
  abstract    = {In the context of post-hoc interpretability, this paper addresses the task of explaining the prediction of a classifier, considering the case where no information is available, neither on the classifier itself, nor on the processed data (neither the training nor the test data). It proposes an instance-based approach whose principle consists in determining the minimal changes needed to alter a prediction: given a data point whose classification must be explained, the proposed method consists in identifying a close neighbour classified differently, where the closeness definition integrates a sparsity constraint. This principle is implemented using observation generation in the Growing Spheres algorithm. Experimental results on two datasets illustrate the relevance of the proposed approach that can be used to gain knowledge about the classifier.},
  annotation  = {Comment: preprint},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1712.08443.pdf:application/pdf},
  keywords    = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@TechReport{delaney2021uncertainty,
  author      = {Delaney, Eoin and Greene, Derek and Keane, Mark T.},
  date        = {2021-07},
  institution = {arXiv},
  title       = {Uncertainty {Estimation} and {Out}-of-{Distribution} {Detection} for {Counterfactual} {Explanations}: {Pitfalls} and {Solutions}},
  note        = {arXiv:2107.09734 [cs] type: article},
  url         = {http://arxiv.org/abs/2107.09734},
  urldate     = {2023-06-23},
  abstract    = {Whilst an abundance of techniques have recently been proposed to generate counterfactual explanations for the predictions of opaque black-box systems, markedly less attention has been paid to exploring the uncertainty of these generated explanations. This becomes a critical issue in high-stakes scenarios, where uncertain and misleading explanations could have dire consequences (e.g., medical diagnosis and treatment planning). Moreover, it is often difficult to determine if the generated explanations are well grounded in the training data and sensitive to distributional shifts. This paper proposes several practical solutions that can be leveraged to solve these problems by establishing novel connections with other research works in explainability (e.g., trust scores) and uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments demonstrate the utility of our proposed solutions.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2107.09734.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
  shorttitle  = {Uncertainty {Estimation} and {Out}-of-{Distribution} {Detection} for {Counterfactual} {Explanations}},
}

@InProceedings{casanueva2020efficient,
  author    = {Casanueva, Iñigo and Temčinas, Tadas and Gerz, Daniela and Henderson, Matthew and Vulić, Ivan},
  booktitle = {Proceedings of the 2nd {Workshop} on {Natural} {Language} {Processing} for {Conversational} {AI}},
  date      = {2020-07},
  title     = {Efficient {Intent} {Detection} with {Dual} {Sentence} {Encoders}},
  doi       = {10.18653/v1/2020.nlp4convai-1.5},
  location  = {Online},
  pages     = {38--45},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.nlp4convai-1.5},
  urldate   = {2023-06-27},
  abstract  = {Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that: 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent); 3) our intent detectors can be trained in a matter of minutes on a single CPU; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.},
  file      = {Full Text PDF:https\://aclanthology.org/2020.nlp4convai-1.5.pdf:application/pdf},
}

@TechReport{liu2019roberta,
  author      = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  date        = {2019-07},
  institution = {arXiv},
  title       = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
  doi         = {10.48550/arXiv.1907.11692},
  note        = {arXiv:1907.11692 [cs] type: article},
  url         = {http://arxiv.org/abs/1907.11692},
  urldate     = {2023-06-27},
  abstract    = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1907.11692.pdf:application/pdf},
  keywords    = {Computer Science - Computation and Language},
  shorttitle  = {{RoBERTa}},
}

@TechReport{kunstner2020limitations,
  author      = {Kunstner, Frederik and Balles, Lukas and Hennig, Philipp},
  date        = {2020-06},
  institution = {arXiv},
  title       = {Limitations of the {Empirical} {Fisher} {Approximation} for {Natural} {Gradient} {Descent}},
  doi         = {10.48550/arXiv.1905.12558},
  note        = {arXiv:1905.12558 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1905.12558},
  urldate     = {2023-06-30},
  abstract    = {Natural gradient descent, which preconditions a gradient descent update with the Fisher information matrix of the underlying statistical model, is a way to capture partial second-order information. Several highly visible works have advocated an approximation known as the empirical Fisher, drawing connections between approximate second-order methods and heuristics like Adam. We dispute this argument by showing that the empirical Fisher---unlike the Fisher---does not generally capture second-order information. We further argue that the conditions under which the empirical Fisher approaches the Fisher (and the Hessian) are unlikely to be met in practice, and that, even on simple optimization problems, the pathologies of the empirical Fisher can have undesirable effects.},
  annotation  = {Comment: V3: Minor corrections (typographic errors)},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1905.12558.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@TechReport{botev2017practical,
  author      = {Botev, Aleksandar and Ritter, Hippolyt and Barber, David},
  date        = {2017-06},
  institution = {arXiv},
  title       = {Practical {Gauss}-{Newton} {Optimisation} for {Deep} {Learning}},
  doi         = {10.48550/arXiv.1706.03662},
  note        = {arXiv:1706.03662 [stat] type: article},
  url         = {http://arxiv.org/abs/1706.03662},
  urldate     = {2023-06-30},
  abstract    = {We present an efficient block-diagonal ap- proximation to the Gauss-Newton matrix for feedforward neural networks. Our result- ing algorithm is competitive against state- of-the-art first order optimisation methods, with sometimes significant improvement in optimisation performance. Unlike first-order methods, for which hyperparameter tuning of the optimisation parameters is often a labo- rious process, our approach can provide good performance even when used with default set- tings. A side result of our work is that for piecewise linear transfer functions, the net- work objective function can have no differ- entiable local maxima, which may partially explain why such transfer functions facilitate effective optimisation.},
  annotation  = {Comment: ICML 2017},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1706.03662.pdf:application/pdf},
  keywords    = {Statistics - Machine Learning},
}

@TechReport{sharma2021sketching,
  author      = {Sharma, Apoorva and Azizan, Navid and Pavone, Marco},
  date        = {2021-02},
  institution = {arXiv},
  title       = {Sketching {Curvature} for {Efficient} {Out}-of-{Distribution} {Detection} for {Deep} {Neural} {Networks}},
  doi         = {10.48550/arXiv.2102.12567},
  note        = {arXiv:2102.12567 [cs] type: article},
  url         = {http://arxiv.org/abs/2102.12567},
  urldate     = {2023-06-30},
  abstract    = {In order to safely deploy Deep Neural Networks (DNNs) within the perception pipelines of real-time decision making systems, there is a need for safeguards that can detect out-of-training-distribution (OoD) inputs both efficiently and accurately. Building on recent work leveraging the local curvature of DNNs to reason about epistemic uncertainty, we propose Sketching Curvature of OoD Detection (SCOD), an architecture-agnostic framework for equipping any trained DNN with a task-relevant epistemic uncertainty estimate. Offline, given a trained model and its training data, SCOD employs tools from matrix sketching to tractably compute a low-rank approximation of the Fisher information matrix, which characterizes which directions in the weight space are most influential on the predictions over the training data. Online, we estimate uncertainty by measuring how much perturbations orthogonal to these directions can alter predictions at a new test input. We apply SCOD to pre-trained networks of varying architectures on several tasks, ranging from regression to classification. We demonstrate that SCOD achieves comparable or better OoD detection performance with lower computational burden relative to existing baselines.},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2102.12567.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning},
}

@TechReport{amini2019spatial,
  author      = {Amini, Alexander and Soleimany, Ava and Karaman, Sertac and Rus, Daniela},
  date        = {2019-05},
  institution = {arXiv},
  title       = {Spatial {Uncertainty} {Sampling} for {End}-to-{End} {Control}},
  doi         = {10.48550/arXiv.1805.04829},
  note        = {arXiv:1805.04829 [cs] type: article},
  url         = {http://arxiv.org/abs/1805.04829},
  urldate     = {2023-06-30},
  abstract    = {End-to-end trained neural networks (NNs) are a compelling approach to autonomous vehicle control because of their ability to learn complex tasks without manual engineering of rule-based decisions. However, challenging road conditions, ambiguous navigation situations, and safety considerations require reliable uncertainty estimation for the eventual adoption of full-scale autonomous vehicles. Bayesian deep learning approaches provide a way to estimate uncertainty by approximating the posterior distribution of weights given a set of training data. Dropout training in deep NNs approximates Bayesian inference in a deep Gaussian process and can thus be used to estimate model uncertainty. In this paper, we propose a Bayesian NN for end-to-end control that estimates uncertainty by exploiting feature map correlation during training. This approach achieves improved model fits, as well as tighter uncertainty estimates, than traditional element-wise dropout. We evaluate our algorithms on a challenging dataset collected over many different road types, times of day, and weather conditions, and demonstrate how uncertainties can be used in conjunction with a human controller in a parallel autonomous setting.},
  annotation  = {Comment: Originally published in Neural Information Processing Systems (NIPS) Workshop on Bayesian Deep Learning 2017},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1805.04829.pdf:application/pdf},
  keywords    = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@InProceedings{lecun1989optimal,
  author    = {LeCun, Yann and Denker, John and Solla, Sara},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  date      = {1989},
  title     = {Optimal {Brain} {Damage}},
  publisher = {Morgan-Kaufmann},
  url       = {https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html},
  urldate   = {2023-06-30},
  volume    = {2},
  abstract  = {We  have used  information-theoretic ideas  to derive  a class of prac(cid:173) tical  and  nearly  optimal schemes  for  adapting the size  of a  neural  network.  By  removing  unimportant  weights  from  a  network,  sev(cid:173) eral  improvements  can  be  expected:  better  generalization,  fewer  training examples required,  and improved speed  of learning and/or  classification.  The  basic  idea  is  to  use  second-derivative  informa(cid:173) tion to make a  tradeoff between  network  complexity  and  training  set error.  Experiments confirm  the usefulness  of the methods on a  real-world  application.},
  file      = {Full Text PDF:https\://proceedings.neurips.cc/paper_files/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf:application/pdf},
}

@TechReport{martens2020optimizing,
  author      = {Martens, James and Grosse, Roger},
  date        = {2020-06},
  institution = {arXiv},
  title       = {Optimizing {Neural} {Networks} with {Kronecker}-factored {Approximate} {Curvature}},
  doi         = {10.48550/arXiv.1503.05671},
  note        = {arXiv:1503.05671 [cs, stat] type: article},
  url         = {http://arxiv.org/abs/1503.05671},
  urldate     = {2023-06-30},
  abstract    = {We propose an efficient method for approximating natural gradient descent in neural networks which we call Kronecker-Factored Approximate Curvature (K-FAC). K-FAC is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse. It is derived by approximating various large blocks of the Fisher (corresponding to entire layers) as being the Kronecker product of two much smaller matrices. While only several times more expensive to compute than the plain stochastic gradient, the updates produced by K-FAC make much more progress optimizing the objective, which results in an algorithm that can be much faster than stochastic gradient descent with momentum in practice. And unlike some previously proposed approximate natural-gradient/Newton methods which use high-quality non-diagonal curvature matrices (such as Hessian-free optimization), K-FAC works very well in highly stochastic optimization regimes. This is because the cost of storing and inverting K-FAC's approximation to the curvature matrix does not depend on the amount of data used to estimate it, which is a feature typically associated only with diagonal or low-rank approximations to the curvature matrix.},
  annotation  = {Comment: Reduction ratio formula corrected. Removed incorrect claim about geodesics in footnote},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/1503.05671.pdf:application/pdf},
  keywords    = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@TechReport{fong2021conformal,
  author      = {Fong, Edwin and Holmes, Chris},
  date        = {2021-06},
  institution = {arXiv},
  title       = {Conformal {Bayesian} {Computation}},
  doi         = {10.48550/arXiv.2106.06137},
  note        = {arXiv:2106.06137 [stat] type: article},
  url         = {http://arxiv.org/abs/2106.06137},
  urldate     = {2023-07-19},
  abstract    = {We develop scalable methods for producing conformal Bayesian predictive intervals with finite sample calibration guarantees. Bayesian posterior predictive distributions, \$p(y {\textbackslash}mid x)\$, characterize subjective beliefs on outcomes of interest, \$y\$, conditional on predictors, \$x\$. Bayesian prediction is well-calibrated when the model is true, but the predictive intervals may exhibit poor empirical coverage when the model is misspecified, under the so called \$\{{\textbackslash}cal\{M\}\}\$-open perspective. In contrast, conformal inference provides finite sample frequentist guarantees on predictive confidence intervals without the requirement of model fidelity. Using 'add-one-in' importance sampling, we show that conformal Bayesian predictive intervals are efficiently obtained from re-weighted posterior samples of model parameters. Our approach contrasts with existing conformal methods that require expensive refitting of models or data-splitting to achieve computational efficiency. We demonstrate the utility on a range of examples including extensions to partially exchangeable settings such as hierarchical models.},
  annotation  = {Comment: 19 pages, 4 figures, 12 tables; added references and fixed typos},
  file        = {arXiv Fulltext PDF:https\://arxiv.org/pdf/2106.06137.pdf:application/pdf},
  keywords    = {Statistics - Methodology, Statistics - Computation},
}

@Book{hyndman2018forecasting,
  author     = {Hyndman, Rob J. and Athanasopoulos, George},
  date       = {2018-05},
  title      = {Forecasting: principles and practice},
  isbn       = {9780987507112},
  language   = {en},
  note       = {Google-Books-ID: \_bBhDwAAQBAJ},
  publisher  = {OTexts},
  abstract   = {Forecasting is required in many situations. Stocking an inventory may require forecasts of demand months in advance. Telecommunication routing requires traffic forecasts a few minutes ahead. Whatever the circumstances or time horizons involved, forecasting is an important aid in effective and efficient planning.This textbook provides a comprehensive introduction to forecasting methods and presents enough information about each method for readers to use them sensibly.},
  file       = {Google Books Link:https\://books.google.com/books?id=_bBhDwAAQBAJ:text/html},
  keywords   = {Business \& Economics / Forecasting, Business \& Economics / Statistics, Computers / Databases / Data Mining, Computers / Mathematical \& Statistical Software},
  shorttitle = {Forecasting},
}

@InProceedings{xu2021conformal,
  author    = {Xu, Chen and Xie, Yao},
  date      = {2021-07},
  title     = {Conformal prediction interval for dynamic time-series},
  language  = {en},
  pages     = {11559--11569},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v139/xu21h.html},
  urldate   = {2023-07-24},
  abstract  = {We develop a method to construct distribution-free prediction intervals for dynamic time-series, called {\textbackslash}Verb{\textbar}EnbPI{\textbar} that wraps around any bootstrap ensemble estimator to construct sequential prediction intervals. {\textbackslash}Verb{\textbar}EnbPI{\textbar} is closely related to the conformal prediction (CP) framework but does not require data exchangeability. Theoretically, these intervals attain finite-sample, {\textbackslash}textit\{approximately valid\} marginal coverage for broad classes of regression functions and time-series with strongly mixing stochastic errors. Computationally, {\textbackslash}Verb{\textbar}EnbPI{\textbar} avoids overfitting and requires neither data-splitting nor training multiple ensemble estimators; it efficiently aggregates bootstrap estimators that have been trained. In general, {\textbackslash}Verb{\textbar}EnbPI{\textbar} is easy to implement, scalable to producing arbitrarily many prediction intervals sequentially, and well-suited to a wide range of regression functions. We perform extensive real-data analyses to demonstrate its effectiveness.},
  file      = {Full Text PDF:http\://proceedings.mlr.press/v139/xu21h/xu21h.pdf:application/pdf},
  issn      = {2640-3498},
}

@Comment{jabref-meta: databaseType:biblatex;}
