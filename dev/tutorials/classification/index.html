<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Classification ¬∑ ConformalPrediction.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://pat-alt.github.io/ConformalPrediction.jl/tutorials/classification/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="ConformalPrediction.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ConformalPrediction.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">üè† Home</a></li><li><span class="tocitem">ü´£ Tutorials</span><ul><li><a class="tocitem" href="../">Overview</a></li><li class="is-active"><a class="tocitem" href>Classification</a><ul class="internal"><li><a class="tocitem" href="#Split-Conformal-Classification"><span>Split Conformal Classification</span></a></li><li><a class="tocitem" href="#Adaptive-Sets"><span>Adaptive Sets</span></a></li><li><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../regression/">Regression</a></li><li><a class="tocitem" href="../plotting/">Visualizations</a></li></ul></li><li><span class="tocitem">ü´° How-To Guides</span><ul><li><a class="tocitem" href="../../how_to_guides/">Overview</a></li><li><a class="tocitem" href="../../how_to_guides/mnist/">How to Conformalize a Deep Image Classifier</a></li></ul></li><li><span class="tocitem">ü§ì Explanation</span><ul><li><a class="tocitem" href="../../explanation/">Overview</a></li><li><a class="tocitem" href="../../explanation/architecture/">Package Architecture</a></li></ul></li><li><a class="tocitem" href="../../_reference/">üßê Reference</a></li><li><a class="tocitem" href="../../contribute/">üõ† Contribute</a></li><li><a class="tocitem" href="../../faq/">‚ùì FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">ü´£ Tutorials</a></li><li class="is-active"><a href>Classification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Classification</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pat-alt/ConformalPrediction.jl/blob/main/docs/src/tutorials/classification.md#" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Classification"><a class="docs-heading-anchor" href="#Classification">Classification</a><a id="Classification-1"></a><a class="docs-heading-anchor-permalink" href="#Classification" title="Permalink"></a></h1><p>This tutorial is based in parts on this <a href="https://www.paltmeyer.com/blog/posts/conformal-prediction/">blog post</a>.</p><h2 id="Split-Conformal-Classification"><a class="docs-heading-anchor" href="#Split-Conformal-Classification">Split Conformal Classification</a><a id="Split-Conformal-Classification-1"></a><a class="docs-heading-anchor-permalink" href="#Split-Conformal-Classification" title="Permalink"></a></h2><p>We consider a simple binary classification problem. Let (<em>X</em><em>(<em>i</em>),<em>Y</em></em>(<em>i</em>)),¬†<em>i</em>‚ÄÑ=‚ÄÑ1,‚ÄÜ...,‚ÄÜ<em>n</em> denote our feature-label pairs and let <em>Œº</em>‚ÄÑ:‚ÄÑùí≥‚ÄÑ‚Ü¶‚ÄÑùí¥ denote the mapping from features to labels. For illustration purposes we will use the moons dataset üåô. Using <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> we first generate the data and split into into a training and test set:</p><pre><code class="language-julia hljs">using MLJ
using Random
Random.seed!(123)

# Data:
X, y = make_moons(500; noise=0.15)
train, test = partition(eachindex(y), 0.8, shuffle=true)</code></pre><p>Here we will use a specific case of CP called <em>split conformal prediction</em> which can then be summarized as follows:[1]</p><ol><li>Partition the training into a proper training set and a separate calibration set: ùíü_(<em>n</em>)‚ÄÑ=‚ÄÑùíü^(train)‚ÄÖ‚à™‚ÄÖùíü^(cali).</li><li>Train the machine learning model on the proper training set: <em>ŒºÃÇ</em><em>(<em>i</em>‚ÄÑ‚àà‚ÄÑùíü^(train))(<em>X</em></em>(<em>i</em>),<em>Y</em>_(<em>i</em>)).</li><li>Compute nonconformity scores, ùíÆ, using the calibration data ùíü^(cali) and the fitted model <em>ŒºÃÇ</em>_(<em>i</em>‚ÄÑ‚àà‚ÄÑùíü^(train)).</li><li>For a user-specified desired coverage ratio (1‚àí<em>Œ±</em>) compute the corresponding quantile, <em>qÃÇ</em>, of the empirical distribution of nonconformity scores, ùíÆ.</li><li>For the given quantile and test sample <em>X</em>_(test), form the corresponding conformal prediction set:</li></ol><p><em>C</em>(<em>X</em><em>(test))‚ÄÑ=‚ÄÑ{<em>y</em>‚ÄÑ:‚ÄÑ<em>s</em>(<em>X</em></em>(test),<em>y</em>)‚ÄÑ‚â§‚ÄÑ<em>qÃÇ</em>}‚Ää‚ÄÅ‚ÄÅ(1)</p><p>This is the default procedure used for classification and regression in <a href="https://github.com/pat-alt/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>.</p><p>Now let‚Äôs take this to our üåô data. To illustrate the package functionality we will demonstrate the envisioned workflow. We first define our atomic machine learning model following standard <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> conventions. Using <a href="https://github.com/pat-alt/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> we then wrap our atomic model in a conformal model using the standard API call <code>conformal_model(model::Supervised; kwargs...)</code>. To train and predict from our conformal model we can then rely on the conventional <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> procedure again. In particular, we wrap our conformal model in data (turning it into a machine) and then fit it on the training set. Finally, we use our machine to predict the label for a new test sample <code>Xtest</code>:</p><pre><code class="language-julia hljs"># Model:
KNNClassifier = @load KNNClassifier pkg=NearestNeighborModels
model = KNNClassifier(;K=50) 

# Training:
using ConformalPrediction
conf_model = conformal_model(model; coverage=.9)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)

# Conformal Prediction:
Xtest = selectrows(X, test)
ytest = y[test]
yÃÇ = predict(mach, Xtest)
yÃÇ[1]</code></pre><pre><code class="nohighlight hljs">import NearestNeighborModels ‚úî

           UnivariateFinite{Multiclass{2}}      
     ‚îå                                        ‚îê 
   0 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.94   
     ‚îî                                        ‚îò</code></pre><p>The final predictions are set-valued. While the softmax output remains unchanged for the <code>SimpleInductiveClassifier</code>, the size of the prediction set depends on the chosen coverage rate, (1‚àí<em>Œ±</em>).</p><p>When specifying a coverage rate very close to one, the prediction set will typically include many (in some cases all) of the possible labels. Below, for example, both classes are included in the prediction set when setting the coverage rate equal to (1‚àí<em>Œ±</em>)=1.0. This is intuitive, since high coverage quite literally requires that the true label is covered by the prediction set with high probability.</p><pre><code class="language-julia hljs">conf_model = conformal_model(model; coverage=coverage)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)

# Conformal Prediction:
Xtest = (x1=[1],x2=[0])
predict(mach, Xtest)[1]</code></pre><pre><code class="nohighlight hljs">           UnivariateFinite{Multiclass{2}}      
     ‚îå                                        ‚îê 
   0 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.5   
   1 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.5   
     ‚îî                                        ‚îò</code></pre><p>Conversely, for low coverage rates, prediction sets can also be empty. For a choice of (1‚àí<em>Œ±</em>)=0.1, for example, the prediction set for our test sample is empty. This is a bit difficult to think about intuitively and I have not yet come across a satisfactory, intuitive interpretation.[2] When the prediction set is empty, the <code>predict</code> call currently returns <code>missing</code>:</p><pre><code class="language-julia hljs">conf_model = conformal_model(model; coverage=coverage)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)

# Conformal Prediction:
predict(mach, Xtest)[1]</code></pre><pre><code class="nohighlight hljs">missing</code></pre><pre><code class="language-julia hljs">cov_ = .95
conf_model = conformal_model(model; coverage=cov_)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)
Markdown.parse(&quot;&quot;&quot;
The following chart shows the resulting predicted probabilities for ``y=1`` (left) and set size (right) for a choice of ``(1-\\alpha)``=$cov_.
&quot;&quot;&quot;)</code></pre><p>The following chart shows the resulting predicted probabilities for <em>y</em>‚ÄÑ=‚ÄÑ1 (left) and set size (right) for a choice of (1‚àí<em>Œ±</em>)=0.95.</p><pre><code class="language-julia hljs">using Plots
p_proba = contourf(mach.model, mach.fitresult, X, y)
p_set_size = contourf(mach.model, mach.fitresult, X, y; plot_set_size=true)
contourf(p_proba, p_set_size, size=(800,250))</code></pre><p><img src="../classification_files/figure-commonmark/cell-10-output-1.svg" alt/></p><p>The animation below should provide some more intuition as to what exactly is happening here. It illustrates the effect of the chosen coverage rate on the predicted softmax output and the set size in the two-dimensional feature space. Contours are overlayed with the moon data points (including test data). The two samples highlighted in red, <em>X</em>‚ÇÅ and <em>X</em>‚ÇÇ, have been manually added for illustration purposes. Let‚Äôs look at these one by one.</p><p>Firstly, note that <em>X</em>‚ÇÅ (red cross) falls into a region of the domain that is characterized by high predictive uncertainty. It sits right at the bottom-right corner of our class-zero moon üåú (orange), a region that is almost entirely enveloped by our class-one moon üåõ (green). For low coverage rates the prediction set for <em>X</em>‚ÇÅ is empty: on the left-hand side this is indicated by the missing contour for the softmax probability; on the right-hand side we can observe that the corresponding set size is indeed zero. For high coverage rates the prediction set includes both <em>y</em>‚ÄÑ=‚ÄÑ0 and <em>y</em>‚ÄÑ=‚ÄÑ1, indicative of the fact that the conformal classifier is uncertain about the true label.</p><p>With respect to <em>X</em>‚ÇÇ, we observe that while also sitting on the fringe of our class-zero moon, this sample populates a region that is not fully enveloped by data points from the opposite class. In this region, the underlying atomic classifier can be expected to be more certain about its predictions, but still not highly confident. How is this reflected by our corresponding conformal prediction sets?</p><pre><code class="language-julia hljs">Xtest_2 = (x1=[-0.5],x2=[0.25])
pÃÇ_2 = pdf(predict(mach, Xtest_2)[1], 0)</code></pre><p>Well, for low coverage rates (roughly ‚ÄÑ\&lt;‚ÄÑ0.9) the conformal prediction set does not include <em>y</em>‚ÄÑ=‚ÄÑ0: the set size is zero (right panel). Only for higher coverage rates do we have <em>C</em>(<em>X</em>‚ÇÇ)‚ÄÑ=‚ÄÑ{0}: the coverage rate is high enough to include <em>y</em>‚ÄÑ=‚ÄÑ0, but the corresponding softmax probability is still fairly low. For example, for (1‚àí<em>Œ±</em>)‚ÄÑ=‚ÄÑ0.95 we have <em>pÃÇ</em>(<em>y</em>=0|<em>X</em>‚ÇÇ)‚ÄÑ=‚ÄÑ0.72.</p><p>These two examples illustrate an interesting point: for regions characterized by high predictive uncertainty, conformal prediction sets are typically empty (for low coverage) or large (for high coverage). While set-valued predictions may be something to get used to, this notion is overall intuitive.</p><pre><code class="language-julia hljs"># Setup
coverages = range(0.75,1.0,length=5)
n = 100
x1_range = range(extrema(X.x1)...,length=n)
x2_range = range(extrema(X.x2)...,length=n)

anim = @animate for coverage in coverages
    conf_model = conformal_model(model; coverage=coverage)
    mach = machine(conf_model, X, y)
    fit!(mach, rows=train)
    # Probabilities:
    p1 = contourf(mach.model, mach.fitresult, X, y)
    scatter!(p1, Xtest.x1, Xtest.x2, ms=6, c=:red, label=&quot;X‚ÇÅ&quot;, shape=:cross, msw=6)
    scatter!(p1, Xtest_2.x1, Xtest_2.x2, ms=6, c=:red, label=&quot;X‚ÇÇ&quot;, shape=:diamond, msw=6)
    p2 = contourf(mach.model, mach.fitresult, X, y; plot_set_size=true)
    scatter!(p2, Xtest.x1, Xtest.x2, ms=6, c=:red, label=&quot;X‚ÇÅ&quot;, shape=:cross, msw=6)
    scatter!(p2, Xtest_2.x1, Xtest_2.x2, ms=6, c=:red, label=&quot;X‚ÇÇ&quot;, shape=:diamond, msw=6)
    plot(p1, p2, plot_title=&quot;(1-Œ±)=$(round(coverage,digits=2))&quot;, size=(800,300))
end

gif(anim, joinpath(www_path,&quot;classification.gif&quot;), fps=1)</code></pre><p>The effect of the coverage rate on the conformal prediction set. Softmax probabilities are shown on the left. The size of the prediction set is shown on the right.</p><p><img src="../../www/classification.gif" alt/></p><h2 id="Adaptive-Sets"><a class="docs-heading-anchor" href="#Adaptive-Sets">Adaptive Sets</a><a id="Adaptive-Sets-1"></a><a class="docs-heading-anchor-permalink" href="#Adaptive-Sets" title="Permalink"></a></h2><p>Instead of using the simple approach, we can use adaptive prediction sets (Angelopoulos and Bates 2021):</p><pre><code class="language-julia hljs">conf_model = conformal_model(model; coverage=cov_, method=:adaptive_inductive)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)
results[:adaptive_inductive] = mach</code></pre><h2 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h2><p>For evaluation of conformal predictors we follow Angelopoulos and Bates (2021) (Section 3). As a first step towards adaptiveness (adaptivity), the authors recommend to inspect the set size of conformal predictions. The chart below shows the interval width for the different methods along with the ground truth interval width:</p><pre><code class="language-julia hljs">plt_list = []
for (_mod, mach) in results
    push!(plt_list, bar(mach.model, mach.fitresult, X; title=String(_mod)))
end
plot(plt_list..., size=(800,300))</code></pre><p><img src="../classification_files/figure-commonmark/fig-setsize-output-1.svg" alt="Figure¬†1: Prediction interval width."/></p><p>We can also use specific metrics like <strong>empirical coverage</strong> and <strong>size-stratified coverage</strong> to check for correctness and adaptiveness, respectively. To this end, the package provides custom measures that are compatible with <code>MLJ.jl</code>. In other words, we can evaluate model performance in true <code>MLJ.jl</code> fashion (see <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/evaluating_model_performance/">here</a>).</p><p>The code below runs the evaluation with respect to both metrics, <code>emp_coverage</code> and <code>ssc</code> for a single conformal machine:</p><pre><code class="language-julia hljs">_mod, mach = first(results)
_eval = evaluate!(
    mach,
    operation=predict,
    measure=[emp_coverage, ssc]
)
# display(_eval)
println(&quot;Empirical coverage for $(_mod): $(round(_eval.measurement[1], digits=3))&quot;)
println(&quot;SSC for $(_mod): $(round(_eval.measurement[2], digits=3))&quot;)</code></pre><pre><code class="nohighlight hljs">Empirical coverage for adaptive_inductive: 1.0
SSC for adaptive_inductive: 1.0</code></pre><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>Angelopoulos, Anastasios N., and Stephen Bates. 2021. ‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.</p><p>[1] In other places split conformal prediction is sometimes referred to as <em>inductive</em> conformal prediction.</p><p>[2] Any thoughts/comments welcome!</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">¬´ Overview</a><a class="docs-footer-nextpage" href="../regression/">Regression ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Wednesday 14 December 2022 15:15">Wednesday 14 December 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
