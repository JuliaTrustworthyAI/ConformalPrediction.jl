<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>🏠 Home · ConformalPrediction.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://pat-alt.github.io/ConformalPrediction.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ConformalPrediction.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>🏠 Home</a><ul class="internal"><li><a class="tocitem" href="#Quick-Tour"><span>🏃 Quick Tour</span></a></li><li><a class="tocitem" href="#Background"><span>📖 Background</span></a></li><li><a class="tocitem" href="#Installation"><span>🚩 Installation</span></a></li><li><a class="tocitem" href="#Usage-Example"><span>🔍 Usage Example</span></a></li><li><a class="tocitem" href="#Status"><span>🔁 Status</span></a></li><li><a class="tocitem" href="#Contribute"><span>🛠 Contribute</span></a></li><li><a class="tocitem" href="#Thanks"><span>🙏 Thanks</span></a></li><li><a class="tocitem" href="#References"><span>🎓 References</span></a></li></ul></li><li><span class="tocitem">🫣 Tutorials</span><ul><li><a class="tocitem" href="tutorials/">Overview</a></li><li><a class="tocitem" href="tutorials/classification/">Classification</a></li><li><a class="tocitem" href="tutorials/regression/">Regression</a></li><li><a class="tocitem" href="tutorials/plotting/">Visualizations</a></li></ul></li><li><span class="tocitem">🫡 How-To Guides</span><ul><li><a class="tocitem" href="how_to_guides/">Overview</a></li><li><a class="tocitem" href="how_to_guides/mnist/">How to Conformalize a Deep Image Classifier</a></li></ul></li><li><span class="tocitem">🤓 Explanation</span><ul><li><a class="tocitem" href="explanation/">Overview</a></li><li><a class="tocitem" href="explanation/architecture/">Package Architecture</a></li></ul></li><li><a class="tocitem" href="_reference/">🧐 Reference</a></li><li><a class="tocitem" href="contribute/">🛠 Contribute</a></li><li><a class="tocitem" href="faq/">❓ FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>🏠 Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>🏠 Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/pat-alt/ConformalPrediction.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ConformalPrediction"><a class="docs-heading-anchor" href="#ConformalPrediction">ConformalPrediction</a><a id="ConformalPrediction-1"></a><a class="docs-heading-anchor-permalink" href="#ConformalPrediction" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/pat-alt/ConformalPrediction.jl">ConformalPrediction.jl</a>.</p><p><code>ConformalPrediction.jl</code> is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a> (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.</p><h2 id="Quick-Tour"><a class="docs-heading-anchor" href="#Quick-Tour">🏃 Quick Tour</a><a id="Quick-Tour-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Tour" title="Permalink"></a></h2><blockquote><p>First time here? Take a quick interactive <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl">tour</a> to see what this package can do.</p></blockquote><p>The <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl">link</a> takes you to a <a href="https://github.com/fonsp/Pluto.jl"><code>Pluto.jl</code></a> 🎈 notebook hosted on <a href="https://mybinder.org/">binder</a>. In my own experience, this may take some time to load, certainly long enough to get yourself a hot beverage ☕. Alternatively, you can run the notebook locally or skip the tour for now and read on below.</p><h3 id="Local-Tour"><a class="docs-heading-anchor" href="#Local-Tour">Local Tour</a><a id="Local-Tour-1"></a><a class="docs-heading-anchor-permalink" href="#Local-Tour" title="Permalink"></a></h3><p>To run the tour locally, just clone this repo start <code>Pluto.jl</code> as follows:</p><pre><code class="language-julia hljs">] add Pluto
using Pluto
Pluto.run()</code></pre><p>All notebooks are contained in <code>docs/pluto</code>.</p><h2 id="Background"><a class="docs-heading-anchor" href="#Background">📖 Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h2><p>Conformal Prediction is a scalable frequentist approach to uncertainty quantification and coverage control. It promises to be an easy-to-understand, distribution-free and model-agnostic way to generate statistically rigorous uncertainty estimates. Interestingly, it can even be used to complement Bayesian methods.</p><p>The animation below is lifted from a small blog post that introduces the topic and the package ([<a href="https://towardsdatascience.com/conformal-prediction-in-julia-351b81309e30">TDS</a>], [<a href="https://www.paltmeyer.com/blog/posts/conformal-prediction/#fig-anim">Quarto</a>]). It shows conformal prediction sets for two different samples and changing coverage rates. Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage).</p><p><img src="https://raw.githubusercontent.com/pat-alt/blog/main/posts/conformal-prediction/www/medium.gif" alt="Conformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."/></p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">🚩 Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>You can install the latest stable release from the general registry:</p><pre><code class="language-julia hljs">using Pkg
Pkg.add(&quot;ConformalPrediction&quot;)</code></pre><p>The development version can be installed as follows:</p><pre><code class="language-julia hljs">using Pkg
Pkg.add(url=&quot;https://github.com/pat-alt/ConformalPrediction.jl&quot;)</code></pre><h2 id="Usage-Example"><a class="docs-heading-anchor" href="#Usage-Example">🔍 Usage Example</a><a id="Usage-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Usage-Example" title="Permalink"></a></h2><p>To illustrate the intended use of the package, let’s have a quick look at a simple regression problem. We first generate some synthetic data and then determine indices for our training and test data using <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>:</p><pre><code class="language-julia hljs">using MLJ

# Inputs:
N = 600
xmax = 3.0
using Distributions
d = Uniform(-xmax, xmax)
X = rand(d, N)
X = reshape(X, :, 1)

# Outputs:
noise = 0.5
fun(X) = X * sin(X)
ε = randn(N) .* noise
y = @.(fun(X)) + ε
y = vec(y)

# Partition:
train, test = partition(eachindex(y), 0.4, 0.4, shuffle=true)</code></pre><p>We then import a decision-tree based regressor (<a href="https://github.com/Evovest/EvoTrees.jl"><code>EvoTrees.jl</code></a>) following the standard <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a> procedure.</p><pre><code class="language-julia hljs">EvoTreeRegressor = @load EvoTreeRegressor pkg=EvoTrees
model = EvoTreeRegressor(rounds=100) </code></pre><p>To turn our conventional model into a conformal model, we just need to declare it as such by using <code>conformal_model</code> wrapper function. The generated conformal model instance can wrapped in data to create a <em>machine</em>. Finally, we proceed by fitting the machine on training data using the generic <code>fit!</code> method:</p><pre><code class="language-julia hljs">using ConformalPrediction
conf_model = conformal_model(model; method=:jackknife_plus)
mach = machine(conf_model, X, y)
fit!(mach, rows=train)</code></pre><p>Predictions can then be computed using the generic <code>predict</code> method. The code below produces predictions for the first <code>n</code> samples. Each tuple contains the lower and upper bound for the prediction interval.</p><pre><code class="language-julia hljs">show_first = 5
Xtest = selectrows(X, test)
ytest = y[test]
ŷ = predict(mach, Xtest)
ŷ[1:show_first]</code></pre><pre><code class="nohighlight hljs">5-element Vector{Tuple{Float64, Float64}}:
 (0.325476135568554, 2.5420611849529986)
 (-0.8093221495344456, 1.513229072277355)
 (0.24246467414510378, 2.531848511672005)
 (-0.37629465789570005, 1.9144457517084361)
 (-0.5411423339519135, 1.712803571302072)</code></pre><p>For simple models like this one, we can call a custom <code>Plots</code> recipe on our instance, fit result and data to generate the chart below:</p><pre><code class="language-julia hljs">using Plots
zoom = -0.5
plt = plot(mach.model, mach.fitresult, Xtest, ytest, zoom=zoom, observed_lab=&quot;Test points&quot;)
xrange = range(-xmax+zoom,xmax-zoom,length=N)
plot!(plt, xrange, @.(fun(xrange)), lw=1, ls=:dash, colour=:black, label=&quot;Ground truth&quot;)</code></pre><p><img src="index_files/figure-commonmark/cell-7-output-1.svg" alt/></p><p>We can evaluate the conformal model using the standard <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a> workflow with a custom performance measure. You can use either <code>emp_coverage</code> for the overall empirical coverage (correctness) or <code>ssc</code> for the size-stratified coverage rate (adaptiveness).</p><pre><code class="language-julia hljs">_eval = evaluate!(mach; measure=[emp_coverage, ssc], verbosity=0)
display(_eval)
println(&quot;Empirical coverage: $(round(_eval.measurement[1], digits=3))&quot;)
println(&quot;SSC: $(round(_eval.measurement[2], digits=3))&quot;)</code></pre><pre><code class="nohighlight hljs">PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
┌───────────────────────────────────────────────────────────┬───────────┬───────
│ measure                                                   │ operation │ meas ⋯
├───────────────────────────────────────────────────────────┼───────────┼───────
│ emp_coverage (generic function with 1 method)             │ predict   │ 0.95 ⋯
│ size_stratified_coverage (generic function with 1 method) │ predict   │ 0.90 ⋯
└───────────────────────────────────────────────────────────┴───────────┴───────
                                                               3 columns omitted

Empirical coverage: 0.957
SSC: 0.907</code></pre><h2 id="Status"><a class="docs-heading-anchor" href="#Status">🔁 Status</a><a id="Status-1"></a><a class="docs-heading-anchor-permalink" href="#Status" title="Permalink"></a></h2><p>This package is in its early stages of development and therefore still subject to changes to the core architecture and API.</p><h3 id="Implemented-Methodologies"><a class="docs-heading-anchor" href="#Implemented-Methodologies">Implemented Methodologies</a><a id="Implemented-Methodologies-1"></a><a class="docs-heading-anchor-permalink" href="#Implemented-Methodologies" title="Permalink"></a></h3><p>The following CP approaches have been implemented:</p><p><strong>Regression</strong>:</p><ul><li>Inductive</li><li>Naive Transductive</li><li>Jackknife</li><li>Jackknife+</li><li>Jackknife-minmax</li><li>CV+</li><li>CV-minmax</li></ul><p><strong>Classification</strong>:</p><ul><li>Inductive (LABEL (Sadinle, Lei, and Wasserman 2019))</li><li>Naive Transductive</li><li>Adaptive Inductive</li></ul><p>The package has been tested for the following supervised models offered by <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>.</p><p><strong>Regression</strong>:</p><pre><code class="language-julia hljs">keys(tested_atomic_models[:regression])</code></pre><pre><code class="nohighlight hljs">KeySet for a Dict{Symbol, Expr} with 5 entries. Keys:
  :nearest_neighbor
  :evo_tree
  :light_gbm
  :linear
  :decision_tree</code></pre><p><strong>Classification</strong>:</p><pre><code class="language-julia hljs">keys(tested_atomic_models[:classification])</code></pre><pre><code class="nohighlight hljs">KeySet for a Dict{Symbol, Expr} with 5 entries. Keys:
  :nearest_neighbor
  :evo_tree
  :light_gbm
  :decision_tree
  :logistic</code></pre><h3 id="Implemented-Evaluation-Metrics"><a class="docs-heading-anchor" href="#Implemented-Evaluation-Metrics">Implemented Evaluation Metrics</a><a id="Implemented-Evaluation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Implemented-Evaluation-Metrics" title="Permalink"></a></h3><p>To evaluate conformal predictors we are typically interested in correctness and adaptiveness. The former can be evaluated by looking at the empirical coverage rate, while the latter can be assessed through metrics that address the conditional coverage (Angelopoulos and Bates 2021). To this end, the following metrics have been implemented:</p><ul><li><code>emp_coverage</code> (empirical coverage)</li><li><code>ssc</code> (size-stratified coverage)</li></ul><p>There is also a simple <code>Plots.jl</code> recipe that can be used to inspect the set sizes. In the regression case, the interval width is stratified into discrete bins for this purpose:</p><pre><code class="language-julia hljs">bar(mach.model, mach.fitresult, X)</code></pre><p><img src="index_files/figure-commonmark/cell-11-output-1.svg" alt/></p><h2 id="Contribute"><a class="docs-heading-anchor" href="#Contribute">🛠 Contribute</a><a id="Contribute-1"></a><a class="docs-heading-anchor-permalink" href="#Contribute" title="Permalink"></a></h2><p>Contributions are welcome! A good place to start is the <a href="https://github.com/pat-alt/ConformalPrediction.jl/issues">list</a> of outstanding issues. For more details, see also the <a href="https://www.paltmeyer.com/ConformalPrediction.jl/dev/contribute/">Contributor’s Guide</a>. Please follow the <a href="https://github.com/SciML/ColPrac">SciML ColPrac guide</a>.</p><h2 id="Thanks"><a class="docs-heading-anchor" href="#Thanks">🙏 Thanks</a><a id="Thanks-1"></a><a class="docs-heading-anchor-permalink" href="#Thanks" title="Permalink"></a></h2><p>To build this package we have made heavy use of this amazing <a href="https://arxiv.org/abs/2107.07511">tutorial</a> (Angelopoulos and Bates 2021) and also this research <a href="https://arxiv.org/abs/1905.02928">paper</a>. The Awesome Conformal Prediction <a href="https://github.com/valeman/awesome-conformal-prediction">repository</a> (Manokhin, n.d.) has also been a fantastic place to get started. Special thanks also to <a href="https://github.com/aangelopoulos">@aangelopoulos</a>, <a href="https://github.com/valeman">@valeman</a> and others for actively contributing to discussions on here. Finally, many thanks to Anthony Blaom (<a href="https://github.com/ablaom">@ablaom</a>) for many helpful discussions about how to interface this package to <code>MLJ.jl</code>.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">🎓 References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><p>Angelopoulos, Anastasios N., and Stephen Bates. 2021. “A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.” <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.</p><p>Blaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. “MLJ: A Julia Package for Composable Machine Learning.” <em>Journal of Open Source Software</em> 5 (55): 2704. <a href="https://doi.org/10.21105/joss.02704">https://doi.org/10.21105/joss.02704</a>.</p><p>Manokhin, Valery. n.d. “Awesome Conformal Prediction.”</p><p>Sadinle, Mauricio, Jing Lei, and Larry Wasserman. 2019. “Least Ambiguous Set-Valued Classifiers with Bounded Error Levels.” <em>Journal of the American Statistical Association</em> 114 (525): 223–34.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorials/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Monday 12 December 2022 08:21">Monday 12 December 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
