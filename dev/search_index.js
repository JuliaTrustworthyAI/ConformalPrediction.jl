var documenterSearchIndex = {"docs":
[{"location":"classification/simple/#Classification-Tutorial","page":"Tutorial","title":"Classification Tutorial","text":"","category":"section"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"[INCOMPLETE]","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"We firstly generate some synthetic data with three classes and partition it into a training set, a calibration set and a test set:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"using MLJ\nX, y = MLJ.make_blobs(1000, 2, centers=3, cluster_std=2)\ntrain, calibration, test = partition(eachindex(y), 0.4, 0.4)","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Following the standard MLJ procedure, we train a decision tree for the classification task:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\nmodel = DecisionTreeClassifier() \nmach = machine(model, X, y)\nfit!(mach, rows=train)","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Next we instantiate our conformal model and calibrate using the calibration data:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"using ConformalPrediction\nconf_model = conformal_model(model)\ncalibrate!(conf_model, selectrows(X, calibration), y[calibration])","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Using the generic predict method we can generate prediction sets like so:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"predict(conf_model, selectrows(X, rand(test,5)))","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                                                          â”‚\nâ”‚      (1)   Pair[1 => missing, 2 => 0.6448661054062889, 3 => missing]     â”‚\nâ”‚      (2)   Pair[1 => missing, 2 => missing, 3 => 0.8197529347049547]     â”‚\nâ”‚      (3)   Pair[1 => missing, 2 => 0.8229512785953512, 3 => missing]     â”‚\nâ”‚      (4)   Pair[1 => missing, 2 => 0.7858778376049668, 3 => missing]     â”‚\nâ”‚      (5)   Pair[1 => missing, 2 => missing, 3 => 0.8197529347049547]     â”‚\nâ”‚                                                                          â”‚\nâ”‚                                                                          â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5 items â”€â”€â”€â•¯","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = ConformalPrediction","category":"page"},{"location":"reference/#All-functions-and-types","page":"Reference","title":"All functions and types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Exported-functions","page":"Reference","title":"Exported functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [\n    ConformalPrediction,\n    ConformalPrediction.ConformalModels\n]\nPrivate = false","category":"page"},{"location":"reference/#ConformalPrediction.ConformalModels.available_models","page":"Reference","title":"ConformalPrediction.ConformalModels.available_models","text":"A container listing all available methods for conformal prediction.\n\n\n\n\n\n","category":"constant"},{"location":"reference/#ConformalPrediction.ConformalModels.ConformalModel","page":"Reference","title":"ConformalPrediction.ConformalModels.ConformalModel","text":"An abstract base type for conformal models.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.InductiveConformalModel","page":"Reference","title":"ConformalPrediction.ConformalModels.InductiveConformalModel","text":"An abstract base time of Inductive Conformal Models. These models rely on data splitting. In particular, we partition the training data as 1n=mathcalD_texttrain cup mathcalD_textcalibration.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.JackknifeRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.JackknifeRegressor","text":"Constructor for JackknifeRegressor.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.NaiveClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.NaiveClassifier","text":"The NaiveClassifier is the simplest approach to Inductive Conformal Classification. Contrary to the NaiveClassifier it computes nonconformity scores using a designated trainibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.NaiveRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.NaiveRegressor","text":"The NaiveRegressor for conformal prediction is the simplest approach to conformal regression.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.SimpleInductiveClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.SimpleInductiveClassifier","text":"The SimpleInductiveClassifier is the simplest approach to Inductive Conformal Classification. Contrary to the NaiveClassifier it computes nonconformity scores using a designated calibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.SimpleInductiveRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.SimpleInductiveRegressor","text":"The SimpleInductiveRegressor is the simplest approach to Inductive Conformal Regression. Contrary to the NaiveRegressor it computes nonconformity scores using a designated calibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.TransductiveConformalModel","page":"Reference","title":"ConformalPrediction.ConformalModels.TransductiveConformalModel","text":"An abstract base time of Transductive Conformal Models. These models do not rely on data splitting. In particular, nonconformity scores are computed using the entire trainign data set 1n=mathcalD_texttrain.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.calibrate!-Tuple{ConformalPrediction.ConformalModels.InductiveConformalModel, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.calibrate!","text":"calibrate!(conf_model::InductiveConformalModel, Xcal, ycal)\n\nCalibrates a Inductive Conformal Model using calibration data. \n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.conformal_model-Tuple{MLJModelInterface.Supervised}","page":"Reference","title":"ConformalPrediction.ConformalModels.conformal_model","text":"conformal_model(model::Supervised; method::Union{Nothing, Symbol}=nothing)\n\nA simple wrapper function that turns any modeline{<:Supervised} into a conformal model. It accepts an optional key argument that can be used to specify the desired method for conformal prediction.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.predict_region","page":"Reference","title":"ConformalPrediction.ConformalModels.predict_region","text":"predict_region(conf_model::TransductiveConformalRegressor, Xnew, coverage::AbstractFloat=0.95)\n\nGeneric method to compute prediction region for given quantile qÌ‚ for Transductive Conformal Regressors. \n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.predict_region-2","page":"Reference","title":"ConformalPrediction.ConformalModels.predict_region","text":"predict_region(conf_model::InductiveConformalClassifier, Xnew, coverage::AbstractFloat=0.95)\n\nGeneric method to compute prediction region for given quantile qÌ‚ for Inductive Conformal Classifiers. \n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.predict_region-3","page":"Reference","title":"ConformalPrediction.ConformalModels.predict_region","text":"predict_region(conf_model::ConformalModel, Xnew, coverage::AbstractFloat=0.95)\n\nGeneric method for generating prediction regions from a calibrated conformal model for a given quantile.\n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.predict_region-4","page":"Reference","title":"ConformalPrediction.ConformalModels.predict_region","text":"predict_region(conf_model::TransductiveConformalClassifier, Xnew, coverage::AbstractFloat=0.95)\n\nGeneric method to compute prediction region for given quantile qÌ‚ for Transductive Conformal Classifiers. \n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.predict_region-5","page":"Reference","title":"ConformalPrediction.ConformalModels.predict_region","text":"predict_region(conf_model::InductiveConformalRegressor, Xnew, coverage::AbstractFloat=0.95)\n\nGeneric method to compute prediction region for given quantile qÌ‚ for Inductive Conformal Regressors. \n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{ConformalPrediction.ConformalModels.ConformalModel, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::ConformalModel, Xcal, ycal)\n\nGeneric method for computing non-conformity scores for any conformal model using calibration (inductive) or training (transductive) data.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{JackknifeRegressor, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::JackknifeRegressor, Xtrain, ytrain)\n\nFor the JackknifeRegressor prediction intervals are computed as follows,\n\nbeginaligned hatC_nalpha(X_n+1) = hatmu(X_n+1) pm hatq_n alpha^+ Y_i - hatmu_-i(X_i)  i in mathcalD_texttrain endaligned\n\nwhere hatmu_-i denotes the model fitted on training data with ith point removed. The jackknife procedure addresses the overfitting issue associated with the NaiveRegressor.\n\nconf_model = conformal_model(model; method=:jackknife)\nscore(conf_model, X, y)\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{NaiveClassifier, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::NaiveClassifier, Xtrain, ytrain)\n\nFor the NaiveClassifier prediction sets are computed as follows:\n\nbeginaligned hatC_nalpha(X_n+1) = lefty s(X_n+1y) le hatq_n alpha^+ Y_i - hatmu(X_i)  right  i in mathcalD_texttrain endaligned\n\nThe naive approach typically produces prediction regions that undercover due to overfitting.\n\nExamples\n\nconf_model = conformal_model(model; method=:naive)\nscore(conf_model, X, y)\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{NaiveRegressor, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::NaiveRegressor, Xtrain, ytrain)\n\nFor the NaiveRegressor prediction intervals are computed as follows:\n\nbeginaligned hatC_nalpha(X_n+1) = hatmu(X_n+1) pm hatq_n alpha^+ Y_i - hatmu(X_i)   i in mathcalD_texttrain endaligned\n\nThe naive approach typically produces prediction regions that undercover due to overfitting.\n\nconf_model = conformal_model(model; method=:naive)\nscore(conf_model, X, y)\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{SimpleInductiveClassifier, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::SimpleInductiveClassifier, Xtrain, ytrain)\n\nFor the SimpleInductiveClassifier prediction sets are computed as follows,\n\nbeginaligned hatC_nalpha(X_n+1) = lefty s(X_n+1y) le hatq_n alpha^+ Y_i - hatmu(X_i)  right  i in mathcalD_textcalibration endaligned\n\nwhere mathcalD_textcalibration denotes the designated calibration data and hatmu denotes the model fitted on training data mathcalD_texttrain.\n\nExamples\n\nconf_model = conformal_model(model; method=:simple)\nscore(conf_model, X, y)\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{SimpleInductiveRegressor, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::SimpleInductiveRegressor, Xtrain, ytrain)\n\nFor the SimpleInductiveRegressor prediction intervals are computed as follows,\n\nbeginaligned hatC_nalpha(X_n+1) = hatmu(X_n+1) pm hatq_n alpha^+ Y_i - hatmu(X_i)   i in mathcalD_textcalibration endaligned\n\nwhere mathcalD_textcalibration denotes the designated calibration data and hatmu denotes the model fitted on training data mathcalD_texttrain.\n\nExamples\n\nconf_model = conformal_model(model; method=:simple)\nscore(conf_model, X, y)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Internal-functions","page":"Reference","title":"Internal functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [\n    ConformalPrediction,\n    ConformalPrediction.ConformalModels\n]\nPublic = false","category":"page"},{"location":"reference/#ConformalPrediction.ConformalModels.InductiveConformalClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.InductiveConformalClassifier","text":"A base type for Inductive Conformal Classifiers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.InductiveConformalRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.InductiveConformalRegressor","text":"A base type for Inductive Conformal Regressors.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.TransductiveConformalClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.TransductiveConformalClassifier","text":"A base type for Transductive Conformal Classifiers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.TransductiveConformalRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.TransductiveConformalRegressor","text":"A base type for Transductive Conformal Regressors.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.empirical_quantile","page":"Reference","title":"ConformalPrediction.ConformalModels.empirical_quantile","text":"empirical_quantile(conf_model::ConformalModel, coverage::AbstractFloat=0.95)\n\nComputes the empirical quantile qÌ‚ of the calibrated conformal scores for a user chosen coverage rate (1-Î±).\n\n\n\n\n\n","category":"function"},{"location":"reference/#MLJModelInterface.fit-Tuple{ConformalPrediction.ConformalModels.InductiveConformalModel, Any, Any, Any}","page":"Reference","title":"MLJModelInterface.fit","text":"fit(conf_model::InductiveConformalModel, verbosity, X, y)\n\nWrapper function to fit the underlying MLJ model. For Inductive Conformal Prediction the underlying model is fitted on the proper training set. The fitresult is assigned to the model instance. Computation of nonconformity scores requires a separate calibration step involving a calibration data set (see calibrate!). \n\n\n\n\n\n","category":"method"},{"location":"reference/#MLJModelInterface.fit-Tuple{ConformalPrediction.ConformalModels.TransductiveConformalModel, Any, Any, Any}","page":"Reference","title":"MLJModelInterface.fit","text":"fit(conf_model::TransductiveConformalModel, verbosity, X, y)\n\nWrapper function to fit the underlying MLJ model and compute nonconformity scores in one single call. This method is only applicable to Transductive Conformal Prediction.\n\n\n\n\n\n","category":"method"},{"location":"reference/#MLJModelInterface.predict-Tuple{ConformalPrediction.ConformalModels.ConformalModel, Any, Any}","page":"Reference","title":"MLJModelInterface.predict","text":"MMI.predict(conf_model::ConformalModel, fitresult, Xnew)\n\nCompulsory generic predict method of MMI. Simply wraps the underlying model and apply generic method to underlying model.\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = ConformalPrediction","category":"page"},{"location":"#ConformalPrediction","page":"Home","title":"ConformalPrediction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ConformalPrediction.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ. Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.","category":"page"},{"location":"#Disclaimer","page":"Home","title":"Disclaimer âš ï¸","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is in its very early stages of development. In fact, Iâ€™ve built this package largely to gain a better understanding of the topic myself. So far only the most simple approaches have been implemented:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inductive Conformal Regression\nInductive Conformal Classification: LABEL approach for classification (Sadinle, Lei, and Wasserman 2019).\nNaive Transductive Regression\nNaive Transductive Classification\nJackknife Regression","category":"page"},{"location":"","page":"Home","title":"Home","text":"I have only tested it for a few of the supervised models offered by MLJ.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation ğŸš©","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install the first stable release from the general registry:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"ConformalPrediction\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The development version can be installed as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/ConformalPrediction.jl\")","category":"page"},{"location":"#Usage-Example-Inductive-Conformal-Regression","page":"Home","title":"Usage Example - Inductive Conformal Regression ğŸ”","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To illustrate the intended use of the package, letâ€™s have a quick look at a simple regression problem. Using MLJ we first generate some synthetic data and then determine indices for our training, calibration and test data:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MLJ\nX, y = MLJ.make_regression(1000, 2)\ntrain, calibration, test = partition(eachindex(y), 0.4, 0.4)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We then train a decision tree (DecisionTree) and follow the standard MLJ training procedure.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\nmodel = DecisionTreeRegressor() ","category":"page"},{"location":"","page":"Home","title":"Home","text":"To turn our conventional machine into a conformal model, we just need to declare it as such by using conformal_model wrapper function. The generated conformal model instance can wrapped in data to create a machine following standard MLJ convention. By default that function instantiates a SimpleInductiveRegressor.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Fitting Inductive Conformal Predictors using fit! trains the underlying machine learning model, but it does not compute nonconformity scores. That is because Inductive Conformal Predictors rely on a separate set of calibration data. Consequently, conformal models of type InductiveConformalModel <: ConformalModel require a separate calibration step to be trained for conformal prediction. This can be implemented by calling the generic calibrate! method on the model instance.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using ConformalPrediction\nconf_model = conformal_model(model)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\ncalibrate!(conf_model, selectrows(X, calibration), y[calibration])","category":"page"},{"location":"","page":"Home","title":"Home","text":"Point predictions for the underlying machine learning model can be computed as always using the generic predict method. The code below produces predictions a random subset of test samples:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Xtest = selectrows(X, rand(test,5))\npredict(mach, Xtest)","category":"page"},{"location":"","page":"Home","title":"Home","text":"â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                    â”‚\nâ”‚      (1)   0.487041919606731       â”‚\nâ”‚      (2)   1.156996084490427       â”‚\nâ”‚      (3)   0.2944027447212445      â”‚\nâ”‚      (4)   -0.5897879862659916     â”‚\nâ”‚      (5)   0.037577444230686       â”‚\nâ”‚                                    â”‚\nâ”‚                                    â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5 items â”€â”€â”€â•¯","category":"page"},{"location":"","page":"Home","title":"Home","text":"Conformal prediction regions can be computed using the predict_region method:","category":"page"},{"location":"","page":"Home","title":"Home","text":"coverage = .90\npredict_region(conf_model, Xtest, coverage)","category":"page"},{"location":"","page":"Home","title":"Home","text":"â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                                                    â”‚\nâ”‚      (1)   [\"lower\" => [0.11529245641527913], \"upper\" =>           â”‚\nâ”‚  [0.8587913827981828]]                                             â”‚\nâ”‚      (2)   [\"lower\" => [0.7852466212989752], \"upper\" =>            â”‚\nâ”‚  [1.5287455476818788]]                                             â”‚\nâ”‚      (3)   [\"lower\" => [-0.07734671847020735], \"upper\" =>          â”‚\nâ”‚  [0.6661522079126964]]                                             â”‚\nâ”‚      (4)   [\"lower\" => [-0.9615374494574435], \"upper\" =>           â”‚\nâ”‚  [-0.21803852307453975]]                                           â”‚\nâ”‚      (5)   [\"lower\" => [-0.33417201896076587], \"upper\" =>          â”‚\nâ”‚  [0.40932690742213784]]                                            â”‚\nâ”‚                                                                    â”‚\nâ”‚                                                                    â”‚\nâ”‚                                                                    â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5 items â”€â”€â”€â•¯","category":"page"},{"location":"#Usage-Example-Transductive-Conformal-Regression","page":"Home","title":"Usage Example - Transductive Conformal Regression ğŸ”","text":"","category":"section"},{"location":"#Naive","page":"Home","title":"Naive","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"conf_model = conformal_model(model; method=:naive)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\npredict_region(conf_model, Xtest, coverage)","category":"page"},{"location":"#Jackknife","page":"Home","title":"Jackknife","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"conf_model = conformal_model(model; method=:jackknife)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\npredict_region(conf_model, Xtest, coverage)","category":"page"},{"location":"#Contribute","page":"Home","title":"Contribute ğŸ› ","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Contributions are welcome! Please follow the SciML ColPrac guide.","category":"page"},{"location":"#References","page":"Home","title":"References ğŸ“","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Sadinle, Mauricio, Jing Lei, and Larry Wasserman. 2019. â€œLeast Ambiguous Set-Valued Classifiers with Bounded Error Levels.â€ Journal of the American Statistical Association 114 (525): 223â€“34.","category":"page"}]
}
