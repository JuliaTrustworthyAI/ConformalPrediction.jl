var documenterSearchIndex = {"docs":
[{"location":"classification/simple/#Classification-Tutorial","page":"Tutorial","title":"Classification Tutorial","text":"","category":"section"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"[INCOMPLETE]","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"We firstly generate some synthetic data with three classes and partition it into a training set, a calibration set and a test set:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"using MLJ\nX, y = MLJ.make_blobs(1000, 2, centers=3, cluster_std=2)\ntrain, calibration, test = partition(eachindex(y), 0.4, 0.4)","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Following the standard MLJ procedure, we train a decision tree for the classification task:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree\nmodel = DecisionTreeClassifier() \nmach = machine(model, X, y)\nfit!(mach, rows=train)","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Next we instantiate our conformal model and calibrate using the calibration data:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"using ConformalPrediction\nconf_model = conformal_model(model)\ncalibrate!(conf_model, selectrows(X, calibration), y[calibration])","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"Using the generic predict method we can generate prediction sets like so:","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"predict(conf_model, selectrows(X, rand(test,5)))","category":"page"},{"location":"classification/simple/","page":"Tutorial","title":"Tutorial","text":"╭──────────────────────────────────────────────────────────────────────────╮\n│                                                                          │\n│      (1)   Pair[1 => missing, 2 => 0.6448661054062889, 3 => missing]     │\n│      (2)   Pair[1 => missing, 2 => missing, 3 => 0.8197529347049547]     │\n│      (3)   Pair[1 => missing, 2 => 0.8229512785953512, 3 => missing]     │\n│      (4)   Pair[1 => missing, 2 => 0.7858778376049668, 3 => missing]     │\n│      (5)   Pair[1 => missing, 2 => missing, 3 => 0.8197529347049547]     │\n│                                                                          │\n│                                                                          │\n╰────────────────────────────────────────────────────────────── 5 items ───╯","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = ConformalPrediction","category":"page"},{"location":"reference/#All-functions-and-types","page":"Reference","title":"All functions and types","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/#Exported-functions","page":"Reference","title":"Exported functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [\n    ConformalPrediction,\n    ConformalPrediction.ConformalModels\n]\nPrivate = false","category":"page"},{"location":"reference/#ConformalPrediction.ConformalModels.available_models","page":"Reference","title":"ConformalPrediction.ConformalModels.available_models","text":"A container listing all available methods for conformal prediction.\n\n\n\n\n\n","category":"constant"},{"location":"reference/#ConformalPrediction.ConformalModels.ConformalModel","page":"Reference","title":"ConformalPrediction.ConformalModels.ConformalModel","text":"An abstract base type for conformal models.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.JackknifeRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.JackknifeRegressor","text":"The Jackknife ...\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.NaiveClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.NaiveClassifier","text":"The NaiveClassifier is the simplest approach to Inductive Conformal Classification. Contrary to the NaiveClassifier it computes nonconformity scores using a designated trainibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.NaiveRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.NaiveRegressor","text":"The NaiveRegressor for conformal prediction is the simplest approach to conformal regression. It computes nonconformity scores by simply using the training data.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.SimpleInductiveClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.SimpleInductiveClassifier","text":"The SimpleInductiveClassifier is the simplest approach to Inductive Conformal Classification. Contrary to the NaiveClassifier it computes nonconformity scores using a designated calibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.SimpleInductiveRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.SimpleInductiveRegressor","text":"The SimpleInductiveRegressor is the simplest approach to Inductive Conformal Regression. Contrary to the NaiveRegressor it computes nonconformity scores using a designated calibration dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.calibrate!-Tuple{ConformalPrediction.ConformalModels.InductiveConformalModel, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.calibrate!","text":"calibrate!(conf_model::InductiveConformalModel, Xcal, ycal)\n\nCalibrates a Inductive Conformal Model using calibration data. \n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.conformal_model-Tuple{MLJModelInterface.Supervised}","page":"Reference","title":"ConformalPrediction.ConformalModels.conformal_model","text":"conformal_model(model::Supervised; method::Union{Nothing, Symbol}=nothing)\n\nA simple wrapper function that turns any modeline{<:Supervised} into a conformal model. It accepts an optional key argument that can be used to specify the desired method for conformal prediction.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.empirical_quantile","page":"Reference","title":"ConformalPrediction.ConformalModels.empirical_quantile","text":"empirical_quantile(conf_model::ConformalModel, coverage::AbstractFloat=0.95)\n\nComputes the empirical quantile q̂ of the calibrated conformal scores for a user chosen coverage rate (1-α).\n\n\n\n\n\n","category":"function"},{"location":"reference/#ConformalPrediction.ConformalModels.prediction_region-Tuple{ConformalPrediction.ConformalModels.ConformalModel, Any, Real}","page":"Reference","title":"ConformalPrediction.ConformalModels.prediction_region","text":"prediction_region(conf_model::ConformalModel, Xnew, q̂::Real)\n\nGeneric method for generating prediction regions from a calibrated conformal model for a given quantile.\n\n\n\n\n\n","category":"method"},{"location":"reference/#ConformalPrediction.ConformalModels.score-Tuple{ConformalPrediction.ConformalModels.ConformalModel, Any, Any}","page":"Reference","title":"ConformalPrediction.ConformalModels.score","text":"score(conf_model::ConformalModel, Xcal, ycal)\n\nGeneric method for computing non-conformity scores for any conformal model using calibration (inductive) or training (transductive) data.\n\n\n\n\n\n","category":"method"},{"location":"reference/#MLJModelInterface.fit-Tuple{ConformalPrediction.ConformalModels.InductiveConformalModel, Any, Any, Any}","page":"Reference","title":"MLJModelInterface.fit","text":"fit(conf_model::InductiveConformalModel, verbosity, X, y)\n\nWrapper function to fit the underlying MLJ model. For Inductive Conformal Prediction the underlying model is fitted on the proper training set. The fitresult is assigned to the model instance. Computation of nonconformity scores requires a separate calibration step involving a calibration data set (see calibrate!). \n\n\n\n\n\n","category":"method"},{"location":"reference/#MLJModelInterface.fit-Tuple{ConformalPrediction.ConformalModels.TransductiveConformalModel, Any, Any, Any}","page":"Reference","title":"MLJModelInterface.fit","text":"fit(conf_model::TransductiveConformalModel, verbosity, X, y)\n\nWrapper function to fit the underlying MLJ model and compute nonconformity scores in one single call. This method is only applicable to Transductive Conformal Prediction.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Internal-functions","page":"Reference","title":"Internal functions","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [\n    ConformalPrediction,\n    ConformalPrediction.ConformalModels\n]\nPublic = false","category":"page"},{"location":"reference/#ConformalPrediction.ConformalModels.InductiveConformalClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.InductiveConformalClassifier","text":"A base type for Inductive Conformal Classifiers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.InductiveConformalRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.InductiveConformalRegressor","text":"A base type for Inductive Conformal Regressors.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.TransductiveConformalClassifier","page":"Reference","title":"ConformalPrediction.ConformalModels.TransductiveConformalClassifier","text":"A base type for Transductive Conformal Classifiers.\n\n\n\n\n\n","category":"type"},{"location":"reference/#ConformalPrediction.ConformalModels.TransductiveConformalRegressor","page":"Reference","title":"ConformalPrediction.ConformalModels.TransductiveConformalRegressor","text":"A base type for Transductive Conformal Regressors.\n\n\n\n\n\n","category":"type"},{"location":"reference/#MLJModelInterface.predict","page":"Reference","title":"MLJModelInterface.predict","text":"MMI.predict(conf_model::ConformalModel, Xnew, coverage::AbstractFloat=0.95)\n\nComputes the conformal prediction for any calibrated conformal model and new data Xnew. The default coverage ratio (1-α) is set to 95%.\n\n\n\n\n\n","category":"function"},{"location":"reference/#MLJModelInterface.predict-Tuple{ConformalPrediction.ConformalModels.ConformalModel, Any, Any}","page":"Reference","title":"MLJModelInterface.predict","text":"MMI.predict(conf_model::ConformalModel, fitresult, Xnew)\n\nCompulsory generic predict method of MMI. Simply wraps the underlying model and apply generic method to underlying model.\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = ConformalPrediction","category":"page"},{"location":"#ConformalPrediction","page":"Home","title":"ConformalPrediction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ConformalPrediction.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ. Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.","category":"page"},{"location":"#Disclaimer","page":"Home","title":"Disclaimer ⚠️","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is in its very early stages of development. In fact, I’ve built this package largely to gain a better understanding of the topic myself. So far only the most simple approaches have been implemented:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inductive Conformal Regression\nInductive Conformal Classification: LABEL approach for classification (Sadinle, Lei, and Wasserman 2019).\nNaive Transductive Regression\nNaive Transductive Classification\nJackknife Regression","category":"page"},{"location":"","page":"Home","title":"Home","text":"I have only tested it for a few of the supervised models offered by MLJ.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation 🚩","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install the first stable release from the general registry:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"ConformalPrediction\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"The development version can be installed as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(url=\"https://github.com/pat-alt/ConformalPrediction.jl\")","category":"page"},{"location":"#Usage-Example-Inductive-Conformal-Regression","page":"Home","title":"Usage Example - Inductive Conformal Regression 🔍","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To illustrate the intended use of the package, let’s have a quick look at a simple regression problem. Using MLJ we first generate some synthetic data and then determine indices for our training, calibration and test data:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using MLJ\nX, y = MLJ.make_regression(1000, 2)\ntrain, calibration, test = partition(eachindex(y), 0.4, 0.4)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We then train a decision tree (DecisionTree) and follow the standard MLJ training procedure.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\nmodel = DecisionTreeRegressor() ","category":"page"},{"location":"","page":"Home","title":"Home","text":"To turn our conventional machine into a conformal model, we just need to declare it as such by using conformal_model wrapper function. The generated conformal model instance can wrapped in data to create a machine following standard MLJ convention. By default that function instantiates a SimpleInductiveRegressor.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Fitting Inductive Conformal Predictors using fit! trains the underlying machine learning model, but it does not compute nonconformity scores. That is because Inductive Conformal Predictors rely on a separate set of calibration data. Consequently, conformal models of type InductiveConformalModel <: ConformalModel require a separate calibration step to be trained for conformal prediction. This can be implemented by calling the generic calibrate! method on the model instance.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using ConformalPrediction\nconf_model = conformal_model(model)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\ncalibrate!(conf_model, selectrows(X, calibration), y[calibration])","category":"page"},{"location":"","page":"Home","title":"Home","text":"Predictions can then be computed using the generic predict method. The code below produces predictions a random subset of test samples:","category":"page"},{"location":"","page":"Home","title":"Home","text":"predict(conf_model, selectrows(X, rand(test,5)))","category":"page"},{"location":"","page":"Home","title":"Home","text":"╭────────────────────────────────────────────────────────────────────╮\n│                                                                    │\n│      (1)   [\"lower\" => [-0.37735918544313646], \"upper\" =>          │\n│  [0.25501123982345947]]                                            │\n│      (2)   [\"lower\" => [-1.2704487485197817], \"upper\" =>           │\n│  [-0.6380783232531857]]                                            │\n│      (3)   [\"lower\" => [-0.2025295551192382], \"upper\" =>           │\n│  [0.4298408701473577]]                                             │\n│      (4)   [\"lower\" => [0.41867048477119345], \"upper\" =>           │\n│  [1.0510409100377893]]                                             │\n│      (5)   [\"lower\" => [0.7474621801245576], \"upper\" =>            │\n│  [1.3798326053911536]]                                             │\n│                                                                    │\n│                                                                    │\n│                                                                    │\n╰──────────────────────────────────────────────────────── 5 items ───╯","category":"page"},{"location":"#Contribute","page":"Home","title":"Contribute 🛠","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Contributions are welcome! Please follow the SciML ColPrac guide.","category":"page"},{"location":"#References","page":"Home","title":"References 🎓","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Sadinle, Mauricio, Jing Lei, and Larry Wasserman. 2019. “Least Ambiguous Set-Valued Classifiers with Bounded Error Levels.” Journal of the American Statistical Association 114 (525): 223–34.","category":"page"}]
}
