{
  "hash": "786d90835a77e5ac8d6c14761a15a6db",
  "result": {
    "markdown": "```@meta\nCurrentModule = ConformalPrediction\n```\n\n# How to Conformalize an Deep Learning Image Classifier in Five Minutes\n\n\n\nDeep Learning is popular and --- for some tasks like image classification --- remarkably powerful. But it is also well-known that Deep Neural Networks (DNN) can be unstable [@goodfellow2014explaining] and poorly calibrated. Conformal Prediction can be used to mitigate these pitfalls. This how-to guide demonstrates how you can build an image classifier in `Flux.jl` and conformalize its predictions.\n\n## The Task at Hand \n\nThe task at hand is to predict the labels of handwritten images of digits using the famous MNIST dataset [@lecun1998mnist]. \n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nusing MLDatasets\nN = 500\nXraw, yraw = MNIST(split=:train)[:]\nXraw = Xraw[:,:,1:N]\nyraw = yraw[1:N]\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nusing MLJ\nX = coerce(Xraw, GrayImage)\ny = coerce(yraw, Multiclass)\n```\n:::\n\n\n## Building the Network\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nusing Flux\nusing MLJFlux\n\nbuilder = MLJFlux.@builder Chain(\n    Flux.flatten,\n    Dense(prod(n_in), 32, relu),\n    Dense(32, n_out)\n)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nImageClassifier = @load ImageClassifier\nclf = ImageClassifier(\n    builder=builder,\n    epochs=10,\n    loss=Flux.crossentropy\n)\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nmach = machine(clf, X, y)\n\nevaluate!(\n    mach,\n    resampling=Holdout(rng=123, fraction_train=0.8),\n    operation=predict_mode,\n    measure=[accuracy]\n)\n```\n:::\n\n\n## Conformalizing the Network\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nusing ConformalPrediction\nconf_model = conformal_model(clf)\nmach = machine(conf_model, X, y)\nfit!(mach)\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nset_sizes = ConformalPrediction.set_size.(predict(mach, X))\ncandidates = findall(set_sizes .> 1)\nchosen = rand(candidates)\ndisplay(predict(mach, X[chosen])[1])\ndisplay(X[chosen])\n```\n\n::: {.cell-output .cell-output-display}\n```\n          UnivariateFinite{Multiclass{10}}      \n     ┌                                        ┐ \n   0 ┤■■ 0.0701684                              \n   7 ┤■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.911558   \n     └                                        ┘ \n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](neural_network_files/figure-commonmark/cell-9-output-2.svg){}\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\n_eval = evaluate!(\n    mach,\n    resampling=Holdout(rng=123, fraction_train=0.8),\n    operation=predict,\n    measure=[emp_coverage, ssc]\n)\nprintln(\"Empirical coverage: $(round(_eval.measurement[1], digits=3))\")\nprintln(\"SSC: $(round(_eval.measurement[2], digits=3))\")\n```\n:::\n\n\n## Results\n\n# References\n\n",
    "supporting": [
      "neural_network_files"
    ],
    "filters": []
  }
}