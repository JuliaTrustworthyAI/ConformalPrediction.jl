{
  "hash": "c56dcfed5fce5fece3f8dd90b08af0bd",
  "result": {
    "markdown": "```@meta\nCurrentModule = ConformalPrediction\n```\n\n# ConformalPrediction\n\nDocumentation for [ConformalPrediction.jl](https://github.com/pat-alt/ConformalPrediction.jl).\n\n```@meta\nCurrentModule = ConformalPrediction\n```\n\n\n\n`ConformalPrediction.jl` is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in [MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic. \n\n## Installation ğŸš©\n\nYou can install the first stable release from the general registry:\n\n```julia\nusing Pkg\nPkg.add(\"ConformalPrediction\")\n```\n\nThe development version can be installed as follows:\n\n```julia\nusing Pkg\nPkg.add(url=\"https://github.com/pat-alt/ConformalPrediction.jl\")\n```\n\n## Status ğŸ”\n\nThis package is in its very early stages of development and therefore still subject to changes to the core architecture. The following approaches have been implemented in the development version:\n\n**Regression**:\n\n- Inductive \n- Naive Transductive \n- Jackknife \n- Jackknife+ \n- Jackknife-minmax\n- CV+\n- CV-minmax\n\n**Classification**:\n\n- Inductive (LABEL [@sadinle2019least])\n- Adaptive Inductive\n\nI have only tested it for a few of the supervised models offered by [MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/).\n\n## Usage Example ğŸ”\n\nTo illustrate the intended use of the package, let's have a quick look at a simple regression problem. Using [MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/) we first generate some synthetic data and then determine indices for our training, calibration and test data:\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nusing MLJ\nX, y = MLJ.make_regression(1000, 2)\ntrain, test = partition(eachindex(y), 0.4, 0.4)\n```\n:::\n\n\nWe then import a decision tree ([DecisionTree](https://github.com/Evovest/DecisionTree.jl)) following the standard [MLJ](https://alan-turing-institute.github.io/MLJ.jl/dev/) procedure.\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nDecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\nmodel = DecisionTreeRegressor() \n```\n:::\n\n\nTo turn our conventional model into a conformal model, we just need to declare it as such by using `conformal_model` wrapper function. The generated conformal model instance can wrapped in data to create a *machine*. Finally, we proceed by fitting the machine on training data using the generic `fit!` method:\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nusing ConformalPrediction\nconf_model = conformal_model(model)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\n```\n:::\n\n\nPredictions can then be computed using the generic `predict` method. The code below produces predictions for the first `n` samples. Each tuple contains the lower and upper bound for the prediction interval.\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nn = 10\nXtest = selectrows(X, first(test,n))\nytest = y[first(test,n)]\npredict(mach, Xtest)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚                                                                  â”‚\nâ”‚       (1)   ([-0.16035036780321532], [1.4939904924997824])       â”‚\nâ”‚       (2)   ([-1.086589388667894], [0.5677514716351038])         â”‚\nâ”‚       (3)   ([-1.086589388667894], [0.5677514716351038])         â”‚\nâ”‚       (4)   ([-1.6661164684544767], [-0.011775608151479156])     â”‚\nâ”‚       (5)   ([-3.0116018507211617], [-1.3572609904181638])       â”‚\nâ”‚       (6)   ([0.5337083913933376], [2.1880492516963352])         â”‚\nâ”‚       (7)   ([-1.2219266921060266], [0.43241416819697115])       â”‚\nâ”‚       (8)   ([-1.6867950029289869], [-0.032454142625989335])     â”‚\nâ”‚       (9)   ([-2.0599181285783263], [-0.4055772682753287])       â”‚\nâ”‚      (10)   ([-0.06499897951385392], [1.5893418807891437])       â”‚\nâ”‚                                                                  â”‚\nâ”‚                                                                  â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10 items â”€â”€â”€â•¯\n```\n:::\n:::\n\n\n## Contribute ğŸ› \n\nContributions are welcome! Please follow the [SciML ColPrac guide](https://github.com/SciML/ColPrac).\n\n## References ğŸ“\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": []
  }
}