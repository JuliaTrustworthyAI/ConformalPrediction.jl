```@meta
CurrentModule = ConformalPrediction
```

# How to Conformalize an Deep Learning Image Classifier in Four Lines of Code

```{julia}
#| echo: false

using Pkg; Pkg.activate("docs")
using Plots
theme(:wong)
```

Deep Learning is popular and --- for some tasks like image classification --- remarkably powerful. But it is also well-known that Deep Neural Networks (DNN) can be unstable [@goodfellow2014explaining] and poorly calibrated. Conformal Prediction can be used to mitigate these pitfalls. This how-to guide demonstrates how you can build an image classifier in `Flux.jl` and conformalize its predictions.

## The Task at Hand 

The task at hand is to predict the labels of handwritten images of digits using the famous MNIST dataset [@lecun1998mnist]. 

```{julia}
using MLDatasets
N = 500
Xraw, yraw = MNIST(split=:train)[:]
Xraw = Xraw[:,:,1:N]
yraw = yraw[1:N]
```

```{julia}
using MLJ
X = coerce(Xraw, GrayImage)
y = coerce(yraw, Multiclass)
```

## Building the Network

```{julia}
using Flux
using MLJFlux

builder = MLJFlux.@builder Chain(
    Flux.flatten,
    Dense(prod(n_in), 32, relu),
    Dense(32, n_out)
)
```

```{julia}
ImageClassifier = @load ImageClassifier
clf = ImageClassifier(
    builder=builder,
    epochs=10,
    loss=Flux.crossentropy
)
```

```{julia}
mach = machine(clf, X, y)

evaluate!(
    mach,
    resampling=Holdout(rng=123, fraction_train=0.8),
    operation=predict_mode,
    measure=[accuracy]
)
```


## Conformalizing the Network

```{julia}
using ConformalPrediction
conf_model = conformal_model(clf; method=:simple_inductive)
mach = machine(conf_model, X, y)
fit!(mach)
```

```{julia}
#| output: true

using Plots
function plot_results(mach, X, y; set_size=1, n_samples=3)

    # Choose images:
    set_sizes = ConformalPrediction.set_size.(predict(mach, X))
    candidates = findall(set_sizes .== set_size)
    @assert length(candidates) > 0 "No sets of size $set_size."
    chosen = sample(candidates, n_samples, replace=false)

    plt_lst = []
    for i in chosen
        ytrue = y[i]
        x = X[i]
        ŷ = predict(mach, x)[1]
        title = join(["$(Int(key)-1) ($(round(val, digits=2)))" for (key, val) in ŷ.prob_given_ref], ", ")
        title = "C={$title}\nytrue=$ytrue"
        plt = plot(x, axis=false)
        annotate!(plt, (14, 31, (title, 10-set_size)))
        push!(plt_lst, plt)
    end

    plot(plt_lst..., size=(n_samples*200, 200), layout=(1,n_samples))
end
```


```{julia}
plot_results(mach, X, y; set_size=1)
```

```{julia}
plot_results(mach, X, y; set_size=2)
```

```{julia}
plot_results(mach, X, y; set_size=3)
```




```{julia}
_eval = evaluate!(
    mach,
    resampling=Holdout(rng=123, fraction_train=0.8),
    operation=predict,
    measure=[emp_coverage, ssc]
)
println("Empirical coverage: $(round(_eval.measurement[1], digits=3))")
println("SSC: $(round(_eval.measurement[2], digits=3))")
```


## Results

# References