{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```@meta\n",
        "CurrentModule = ConformalPrediction\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "include(\"$(pwd())/docs/setup_docs.jl\")\n",
        "eval(setup_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to Conformalize a Language Model\n",
        "\n",
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get labels:\n",
        "df_labels = CSV.read(\"dev/artifacts/data/banking77/labels.csv\", DataFrame, drop=[1])\n",
        "labels = df_labels[:,1]\n",
        "\n",
        "# Get data:\n",
        "df_train = CSV.read(\"dev/artifacts/data/banking77/train.csv\", DataFrame, drop=[1])\n",
        "df_cal = CSV.read(\"dev/artifacts/data/banking77/calibration.csv\", DataFrame, drop=[1])\n",
        "df_full_train = vcat(df_train, df_cal)\n",
        "train_ratio = round(nrow(df_train)/nrow(df_full_train), digits=2)\n",
        "df_test = CSV.read(\"dev/artifacts/data/banking77/test.csv\", DataFrame, drop=[1])\n",
        "\n",
        "# Preprocess data:\n",
        "queries_train, y_train = collect(df_train.text), categorical(df_train.labels .+ 1)\n",
        "queries_cal, y_cal = collect(df_cal.text), categorical(df_cal.labels .+ 1)\n",
        "queries, y = collect(df_full_train.text), categorical(df_full_train.labels .+ 1)\n",
        "queries_test, y_test = collect(df_test.text), categorical(df_test.labels .+ 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HuggingFace Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tkr = hgf\"mrm8488/distilroberta-finetuned-banking77:tokenizer\"\n",
        "mod = hgf\"mrm8488/distilroberta-finetuned-banking77:ForSequenceClassification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "query = [\n",
        "    \"What is the base of the exchange rates?\",\n",
        "    \"Exchange rates for the US dollar.\",\n",
        "]\n",
        "a = encode(tkr, query)\n",
        "b = mod.model(a)\n",
        "c = mod.cls(b.hidden_state)\n",
        "d = softmax(c.logit)\n",
        "[labels[i] for i in Flux.onecold(d)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `MLJ` Models\n",
        "\n",
        "### Full Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "struct IntentClassifier <: MLJBase.Probabilistic\n",
        "    tkr::TextEncoders.AbstractTransformerTextEncoder\n",
        "    mod::HuggingFace.HGFRobertaForSequenceClassification\n",
        "end\n",
        "\n",
        "function IntentClassifier(;\n",
        "    tokenizer::TextEncoders.AbstractTransformerTextEncoder, \n",
        "    model::HuggingFace.HGFRobertaForSequenceClassification,\n",
        ")\n",
        "    IntentClassifier(tkr, mod)\n",
        "end\n",
        "\n",
        "function get_hidden_state(clf::IntentClassifier, query::Union{AbstractString, Vector{<:AbstractString}})\n",
        "    token = encode(clf.tkr, query)\n",
        "    hidden_state = clf.mod.model(token).hidden_state\n",
        "    return hidden_state\n",
        "end\n",
        "\n",
        "# This doesn't actually retrain the model, but it retrieves the classifier object\n",
        "function MLJBase.fit(clf::IntentClassifier, verbosity, X, y)\n",
        "    cache=nothing\n",
        "    report=nothing\n",
        "    fitresult = (clf = clf.mod.cls, labels = levels(y))\n",
        "    return fitresult, cache, report\n",
        "end\n",
        "\n",
        "function MLJBase.predict(clf::IntentClassifier, fitresult, Xnew)\n",
        "    output = fitresult.clf(get_hidden_state(clf,Xnew))\n",
        "    p̂ = UnivariateFinite(fitresult.labels,softmax(output.logit)',pool=missing)\n",
        "    return p̂\n",
        "end\n",
        "\n",
        "MLJBase.target_scitype(clf::IntentClassifier) = AbstractVector{<:Finite}\n",
        "\n",
        "MLJBase.predict_mode(clf::IntentClassifier, fitresult, Xnew) = mode.(MLJBase.predict(clf, fitresult, Xnew))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clf = IntentClassifier(tkr, mod)\n",
        "top_n = 1000\n",
        "fitresult, _, _ = fit(clf, 1, nothing, y_test[1:top_n])\n",
        "@time ŷ = predict(clf, fitresult, queries_test[1:top_n]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Omniscent Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "struct OmniscentClassifier <: MLJBase.Probabilistic end\n",
        "\n",
        "# This doesn't actually retrain the model, but it retrieves the classifier object\n",
        "function MLJBase.fit(clf::OmniscentClassifier, verbosity, X, y)\n",
        "    cache=nothing\n",
        "    report=nothing\n",
        "    fitresult=y\n",
        "    return fitresult, cache, report\n",
        "end\n",
        "\n",
        "function MLJBase.predict(clf::OmniscentClassifier, fitresult, Xnew)\n",
        "    p̂ = UnivariateFinite(fitresult.labels,fitresult,pool=missing)\n",
        "    return p̂\n",
        "end\n",
        "\n",
        "MLJBase.target_scitype(clf::OmniscentClassifier) = AbstractVector{<:Finite}\n",
        "\n",
        "MLJBase.predict_mode(clf::OmniscentClassifier, fitresult, Xnew) = mode.(MLJBase.predict(clf, fitresult, Xnew))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conformal Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cov = 0.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Inductive Conformal Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf_model = conformal_model(clf; coverage=cov, method=:simple_inductive, train_ratio=train_ratio)\n",
        "mach = machine(conf_model, queries, y)\n",
        "@time fit!(mach)\n",
        "ŷ = predict(mach, queries_test[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adaptive Inductive Conformal Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf_model = conformal_model(clf; coverage=cov, method=:adaptive_inductive, train_ratio=train_ratio)\n",
        "mach = machine(conf_model, queries, y)\n",
        "@time fit!(mach)\n",
        "ŷ = predict(mach, queries_test[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.8",
      "language": "julia",
      "display_name": "Julia 1.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}