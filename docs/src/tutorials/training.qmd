# ConformalTraining

```@meta
CurrentModule = ConformalPrediction
```

```{julia}
#| echo: false
include("$(pwd())/docs/setup_docs.jl")
eval(setup_docs)
```


```{julia}
using Random
Random.seed!(123)

# Data:
using MLDatasets
N = 60000
Xraw, yraw = MNIST(split=:train)[:]
Xraw = Xraw[:,:,1:N]
yraw = yraw[1:N]
```

```{julia}
#| output: true
#| label: fig-samples
#| fig-cap: Random samples from the MNIST dataset.

using MLJ
using Images
Ximg = map(x -> convert2image(MNIST, x), eachslice(Xraw, dims=3))
X = hcat(map(x -> vec(x), eachslice(Xraw, dims=3))...) |> 
    permutedims |>
    table
y = coerce(yraw, Multiclass)

n_samples = 10
mosaic(rand(Ximg, n_samples)..., ncol=n_samples)
```


```{julia}
using Flux
using MLJFlux
using ConformalPrediction
using ConformalPrediction.ConformalTraining: ConformalNNClassifier

builder = MLJFlux.@builder Chain(
    Dense(prod(n_in), n_out)
)

bs = 500
epochs = 50
opt = Adam(0.05)
clf = ConformalNNClassifier(epochs=epochs, builder=builder, batch_size=bs, reg_strength_size=0.01, epsilon=0.1)
# clf = NeuralNetworkClassifier(epochs=epochs, builder=builder, batch_size=10)
```


```{julia}
conf_model = conformal_model(clf; method=:simple_inductive)
mach = machine(conf_model, X, y)
train, test = partition(eachindex(y), 0.8, shuffle=true)
fit!(mach, rows=train, verbosity=0)
ineff(MLJBase.predict(mach))
```

```{julia}
println(ineff(MLJBase.predict(mach)))
evaluate!(
    mach,
    resampling=Holdout(rng=123, fraction_train=0.8),
    operation=predict_mode,
    measure=[accuracy]
)
```

```{julia}
#| output: true

_eval = evaluate!(
    mach,
    operation=MLJBase.predict,
    measure=[emp_coverage, ssc, ineff]
)

println("Empirical coverage: $(round(_eval.measurement[1], digits=3))")
println("SSC: $(round(_eval.measurement[2], digits=3))")
println("Inefficiency: $(round(_eval.measurement[3], digits=3))")
```